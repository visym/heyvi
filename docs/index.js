URLS=[
"heyvi/index.html",
"heyvi/recognition.html",
"heyvi/model/index.html",
"heyvi/model/face/index.html",
"heyvi/model/face/recognition.html",
"heyvi/model/face/faster_rcnn.html",
"heyvi/model/face/detection.html",
"heyvi/model/yolov3/index.html",
"heyvi/model/yolov3/network.html",
"heyvi/model/yolov3/utils/index.html",
"heyvi/model/yolov3/utils/parse_config.html",
"heyvi/model/yolov3/utils/utils.html",
"heyvi/model/yolov5/index.html",
"heyvi/model/yolov5/utils/index.html",
"heyvi/model/yolov5/utils/autoanchor.html",
"heyvi/model/yolov5/utils/activations.html",
"heyvi/model/yolov5/utils/metrics.html",
"heyvi/model/yolov5/utils/google_utils.html",
"heyvi/model/yolov5/utils/loss.html",
"heyvi/model/yolov5/utils/torch_utils.html",
"heyvi/model/yolov5/utils/general.html",
"heyvi/model/yolov5/models/index.html",
"heyvi/model/yolov5/models/common.html",
"heyvi/model/yolov5/models/yolo.html",
"heyvi/model/yolov5/models/experimental.html",
"heyvi/model/yolov5/models/export.html",
"heyvi/model/ResNets_3D_PyTorch/index.html",
"heyvi/model/ResNets_3D_PyTorch/resnet.html",
"heyvi/version.html",
"heyvi/label.html",
"heyvi/system.html",
"heyvi/util.html",
"heyvi/sensor.html",
"heyvi/detection.html"
];
INDEX=[
{
"ref":"heyvi",
"url":0,
"doc":" \"Hey Vi!\" HEYVI is a python package for visual AI that provides systems and trained models for activity detection and object tracking in videos. HEYVI provides:  Real time activity detection of the [MEVA activity classes](https: mevadata.org)  Real time visual object tracking in long duration videos  Live streaming of annotated videos to youtube live  Visual AI from RTSP cameras  Getting Started Create a video from a file and track the objects, then create an annotation visualization of the tracked video output (vo)   v = vipy.video.Scene(filename='/path/to/video.mp4').framerate(5) T = heyvi.system.Tracker() vo = T(v).annotate('/path/to/annotation.mp4')   Create a default RTSP camera and stream the privacy preserving annotated video (e.g. pixelated bounding boxes with captions) to a YouTube live stream.   v = heyvi.sensor.rtsp().framerate(5) T = heyvi.system.Tracker() with heyvi.system.YoutubeLive(fps=5, encoder='480p') as s: T(v, frame_callback=lambda im: s(im.pixelize().annotate( )    Customization The following environment varibles may be set by the client to specify live camera streams VIPY_RTSP_URL='rtsp: user@password:127.0.0.1' VIPY_RTSP_URL_0='rtsp: user@password:127.0.0.1' VIPY_RTSP_URL_1='rtsp: user@password:127.0.0.2' VIPY_YOUTUBE_STREAMKEY='xxxx-xxxx-xxxx-xxxx-xxxx' VIPY_CACHE='/home/username/.vipy' Where the environment variables VIPY_RTSP_URL_N are the list of cameras that are returned in  heyvi.sensor.cameralist , and VIPY_RTSP_URL refers to the default RTSP camera in  heyvi.sensor.rtsp . Please refer to the [vipy](https: visym.github.io/vipy) documentation for additional environment variables.  Versioning To determine what heyvi version you are running you can use: >>> heyvi.__version__ >>> heyvi.version.is_at_least('0.0.6')  Contact Visym Labs  "
},
{
"ref":"heyvi.recognition",
"url":1,
"doc":""
},
{
"ref":"heyvi.recognition.ActivityRecognition",
"url":1,
"doc":""
},
{
"ref":"heyvi.recognition.ActivityRecognition.class_to_index",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.index_to_class",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.classlist",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.num_classes",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.fromindex",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.label_confidence",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.activity",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.category",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.category_confidence",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.topk",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.topk_probability",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.temporal_support",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.binary_vector",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.totensor",
"url":1,
"doc":"Return captured lambda function if v=None, else return tensor",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.forward",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.configure_optimizers",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.training_step",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.validation_step",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.validation_epoch_end",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.from_checkpoint",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.PIP_250k",
"url":1,
"doc":"Activity recognition using people in public - 250k stabilized"
},
{
"ref":"heyvi.recognition.PIP_250k.totensor",
"url":1,
"doc":"Return captured lambda function if v=None, else return tensor",
"func":1
},
{
"ref":"heyvi.recognition.PIP_250k.forward",
"url":1,
"doc":"Same as :meth: torch.nn.Module.forward . Args:  args: Whatever you decide to pass into the forward method.  kwargs: Keyword arguments are also possible. Return: Your model's output",
"func":1
},
{
"ref":"heyvi.recognition.PIP_370k",
"url":1,
"doc":"Hooks to be used in LightningModule."
},
{
"ref":"heyvi.recognition.PIP_370k.forward",
"url":1,
"doc":"Same as :meth: torch.nn.Module.forward . Args:  args: Whatever you decide to pass into the forward method.  kwargs: Keyword arguments are also possible. Return: Your model's output",
"func":1
},
{
"ref":"heyvi.recognition.PIP_370k.totensor",
"url":1,
"doc":"Return captured lambda function if v=None, else return tensor",
"func":1
},
{
"ref":"heyvi.recognition.CAP",
"url":1,
"doc":"Hooks to be used in LightningModule."
},
{
"ref":"heyvi.recognition.CAP.forward",
"url":1,
"doc":"Same as :meth: torch.nn.Module.forward . Args:  args: Whatever you decide to pass into the forward method.  kwargs: Keyword arguments are also possible. Return: Your model's output",
"func":1
},
{
"ref":"heyvi.recognition.CAP.validation_step",
"url":1,
"doc":"Operates on a single batch of data from the validation set. In this step you'd might generate examples or calculate anything of interest like accuracy.  code-block python  the pseudocode for these calls val_outs = [] for val_batch in val_data: out = validation_step(val_batch) val_outs.append(out) validation_epoch_end(val_outs) Args: batch: The output of your :class: ~torch.utils.data.DataLoader . batch_idx: The index of this batch. dataloader_idx: The index of the dataloader that produced this batch. (only if multiple val dataloaders used) Return: - Any object or value -  None - Validation will skip to the next batch  code-block python  pseudocode of order val_outs = [] for val_batch in val_data: out = validation_step(val_batch) if defined(\"validation_step_end\"): out = validation_step_end(out) val_outs.append(out) val_outs = validation_epoch_end(val_outs)  code-block python  if you have one val dataloader: def validation_step(self, batch, batch_idx):  .  if you have multiple val dataloaders: def validation_step(self, batch, batch_idx, dataloader_idx=0):  . Examples  CASE 1: A single validation dataset def validation_step(self, batch, batch_idx): x, y = batch  implement your own out = self(x) loss = self.loss(out, y)  log 6 example images  or generated text . or whatever sample_imgs = x[:6] grid = torchvision.utils.make_grid(sample_imgs) self.logger.experiment.add_image('example_images', grid, 0)  calculate acc labels_hat = torch.argmax(out, dim=1) val_acc = torch.sum(y  labels_hat).item() / (len(y)  1.0)  log the outputs! self.log_dict({'val_loss': loss, 'val_acc': val_acc}) If you pass in multiple val dataloaders, :meth: validation_step will have an additional argument. We recommend setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.  code-block python  CASE 2: multiple validation dataloaders def validation_step(self, batch, batch_idx, dataloader_idx=0):  dataloader_idx tells you which dataset this is.  . Note: If you don't need to validate you don't need to implement this method. Note: When the :meth: validation_step is called, the model has been put in eval mode and PyTorch gradients have been disabled. At the end of validation, the model goes back to training mode and gradients are enabled.",
"func":1
},
{
"ref":"heyvi.recognition.CAP.validation_step_end",
"url":1,
"doc":"Use this when validating with dp because :meth: validation_step will operate on only part of the batch. However, this is still optional and only needed for things like softmax or NCE loss. Note: If you later switch to ddp or some other mode, this will still be called so that you don't have to change your code.  code-block python  pseudocode sub_batches = split_batches_for_dp(batch) step_output = [validation_step(sub_batch) for sub_batch in sub_batches] validation_step_end(step_output) Args: step_output: What you return in :meth: validation_step for each batch part. Return: None or anything  code-block python  WITHOUT validation_step_end  if used in DP, this batch is 1/num_gpus large def validation_step(self, batch, batch_idx):  batch is 1/num_gpus big x, y = batch out = self.encoder(x) loss = self.softmax(out) loss = nce_loss(loss) self.log(\"val_loss\", loss)          with validation_step_end to do softmax over the full batch def validation_step(self, batch, batch_idx):  batch is 1/num_gpus big x, y = batch out = self(x) return out def validation_step_end(self, val_step_outputs): for out in val_step_outputs:  . See Also: See the :ref: Multi GPU Training   guide for more details.",
"func":1
},
{
"ref":"heyvi.recognition.CAP.validation_epoch_end",
"url":1,
"doc":"Called at the end of the validation epoch with the outputs of all validation steps.  code-block python  the pseudocode for these calls val_outs = [] for val_batch in val_data: out = validation_step(val_batch) val_outs.append(out) validation_epoch_end(val_outs) Args: outputs: List of outputs you defined in :meth: validation_step , or if there are multiple dataloaders, a list containing a list of outputs for each dataloader. Return: None Note: If you didn't define a :meth: validation_step , this won't be called. Examples: With a single dataloader:  code-block python def validation_epoch_end(self, val_step_outputs): for out in val_step_outputs:  . With multiple dataloaders,  outputs will be a list of lists. The outer list contains one entry per dataloader, while the inner list contains the individual outputs of each validation step for that dataloader.  code-block python def validation_epoch_end(self, outputs): for dataloader_output_result in outputs: dataloader_outs = dataloader_output_result.dataloader_i_outputs self.log(\"final_metric\", final_value)",
"func":1
},
{
"ref":"heyvi.recognition.CAP.totensor",
"url":1,
"doc":"Return captured lambda function if v=None, else return tensor",
"func":1
},
{
"ref":"heyvi.recognition.ActivityDetection",
"url":1,
"doc":"Video Activity Detection Base Class. Usage: This class must be a super-class for an ActivityDetection class with a target model, and should not be called directly. See  heyvi.recognition.CAP_AD for an example. Args (__call__): vi [generator of  vipy.video.Scene ]: The input video to be updated in place with detections. This is a generator which is output from heyvi.detection.MultiscaleVideoTracker.__call__ activityiou [float]: The minimum temporal iou for activity assignment mirror [bool]: If true, encode using the mean of a video encoding and the mirrored video encoding. This is slower as it requires 2x GPU forward passes minprob [float]: The minimum probability for new activity detection trackconf [float]: The minimum object detection confidence for new tracks maxdets [int]: The maximum number of allowable detections per frame. If there are more detections per frame tha maxdets, sort them by confidence and use only the top maxdets best avgdets [int]: The number of allowable detections per frame if throttled buffered [bool]: If true, then buffer streams. This is useful for activity detection on live streams. finalized [bool, int]: If False then do not finalize(), If True finalize() only at the end, If int, then finalize every int frames. This is useful for streaming activity detection on unbounded inputs. Returns: The input video is updated in place."
},
{
"ref":"heyvi.recognition.ActivityDetection.temporal_stride",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityDetection.forward",
"url":1,
"doc":"Overload forward for multi-gpu batch. Don't use torch DataParallel!",
"func":1
},
{
"ref":"heyvi.recognition.ActivityDetection.lrt",
"url":1,
"doc":"top-k with likelihood ratio test with background null hypothesis",
"func":1
},
{
"ref":"heyvi.recognition.ActivityDetection.logit_pooling",
"url":1,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityDetection.softmax",
"url":1,
"doc":"Return a list of lists [(class_label, float(softmax), float(logit)  . ] for all classes and batches",
"func":1
},
{
"ref":"heyvi.recognition.ActivityDetection.finalize",
"url":1,
"doc":"In place filtering of video to finalize",
"func":1
},
{
"ref":"heyvi.recognition.ActivityDetection.totensor",
"url":1,
"doc":"Return captured lambda function if v=None, else return tensor",
"func":1
},
{
"ref":"heyvi.recognition.PIP_370k_AD",
"url":1,
"doc":"heyvi.recognition.PIP_370k_AD(). PIP_370K activity detection"
},
{
"ref":"heyvi.recognition.PIP_370k_AD.forward",
"url":1,
"doc":"Overload forward for multi-gpu batch. Don't use torch DataParallel!",
"func":1
},
{
"ref":"heyvi.recognition.PIP_370k_AD.lrt",
"url":1,
"doc":"top-k with likelihood ratio test with background null hypothesis",
"func":1
},
{
"ref":"heyvi.recognition.PIP_370k_AD.softmax",
"url":1,
"doc":"Return a list of lists [(class_label, float(softmax), float(logit)  . ] for all classes and batches",
"func":1
},
{
"ref":"heyvi.recognition.PIP_370k_AD.finalize",
"url":1,
"doc":"In place filtering of video to finalize",
"func":1
},
{
"ref":"heyvi.recognition.PIP_370k_AD.totensor",
"url":1,
"doc":"Return captured lambda function if v=None, else return tensor",
"func":1
},
{
"ref":"heyvi.recognition.Actev21_AD",
"url":1,
"doc":"heyvi.recognition.Actev21_AD(). Actev21 activity detection, alias for  heyvi.recognition.PIP_370K_AD "
},
{
"ref":"heyvi.recognition.Actev21_AD.forward",
"url":1,
"doc":"Overload forward for multi-gpu batch. Don't use torch DataParallel!",
"func":1
},
{
"ref":"heyvi.recognition.Actev21_AD.lrt",
"url":1,
"doc":"top-k with likelihood ratio test with background null hypothesis",
"func":1
},
{
"ref":"heyvi.recognition.Actev21_AD.softmax",
"url":1,
"doc":"Return a list of lists [(class_label, float(softmax), float(logit)  . ] for all classes and batches",
"func":1
},
{
"ref":"heyvi.recognition.Actev21_AD.finalize",
"url":1,
"doc":"In place filtering of video to finalize",
"func":1
},
{
"ref":"heyvi.recognition.Actev21_AD.totensor",
"url":1,
"doc":"Return captured lambda function if v=None, else return tensor",
"func":1
},
{
"ref":"heyvi.recognition.CAP_AD",
"url":1,
"doc":"heyvi.recognition.CAP_AD(). Consented Activities of People (CAP) Activity Detection"
},
{
"ref":"heyvi.recognition.CAP_AD.forward",
"url":1,
"doc":"Overload forward for multi-gpu batch. Don't use torch DataParallel!",
"func":1
},
{
"ref":"heyvi.recognition.CAP_AD.lrt",
"url":1,
"doc":"top-k with likelihood ratio test with background null hypothesis",
"func":1
},
{
"ref":"heyvi.recognition.CAP_AD.softmax",
"url":1,
"doc":"Return a list of lists [(class_label, float(softmax), float(logit)  . ] for all classes and batches",
"func":1
},
{
"ref":"heyvi.recognition.CAP_AD.finalize",
"url":1,
"doc":"In place filtering of video to finalize",
"func":1
},
{
"ref":"heyvi.recognition.CAP_AD.totensor",
"url":1,
"doc":"Return captured lambda function if v=None, else return tensor",
"func":1
},
{
"ref":"heyvi.recognition.CAP_AD.validation_step",
"url":1,
"doc":"Operates on a single batch of data from the validation set. In this step you'd might generate examples or calculate anything of interest like accuracy.  code-block python  the pseudocode for these calls val_outs = [] for val_batch in val_data: out = validation_step(val_batch) val_outs.append(out) validation_epoch_end(val_outs) Args: batch: The output of your :class: ~torch.utils.data.DataLoader . batch_idx: The index of this batch. dataloader_idx: The index of the dataloader that produced this batch. (only if multiple val dataloaders used) Return: - Any object or value -  None - Validation will skip to the next batch  code-block python  pseudocode of order val_outs = [] for val_batch in val_data: out = validation_step(val_batch) if defined(\"validation_step_end\"): out = validation_step_end(out) val_outs.append(out) val_outs = validation_epoch_end(val_outs)  code-block python  if you have one val dataloader: def validation_step(self, batch, batch_idx):  .  if you have multiple val dataloaders: def validation_step(self, batch, batch_idx, dataloader_idx=0):  . Examples  CASE 1: A single validation dataset def validation_step(self, batch, batch_idx): x, y = batch  implement your own out = self(x) loss = self.loss(out, y)  log 6 example images  or generated text . or whatever sample_imgs = x[:6] grid = torchvision.utils.make_grid(sample_imgs) self.logger.experiment.add_image('example_images', grid, 0)  calculate acc labels_hat = torch.argmax(out, dim=1) val_acc = torch.sum(y  labels_hat).item() / (len(y)  1.0)  log the outputs! self.log_dict({'val_loss': loss, 'val_acc': val_acc}) If you pass in multiple val dataloaders, :meth: validation_step will have an additional argument. We recommend setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.  code-block python  CASE 2: multiple validation dataloaders def validation_step(self, batch, batch_idx, dataloader_idx=0):  dataloader_idx tells you which dataset this is.  . Note: If you don't need to validate you don't need to implement this method. Note: When the :meth: validation_step is called, the model has been put in eval mode and PyTorch gradients have been disabled. At the end of validation, the model goes back to training mode and gradients are enabled.",
"func":1
},
{
"ref":"heyvi.recognition.CAP_AD.validation_step_end",
"url":1,
"doc":"Use this when validating with dp because :meth: validation_step will operate on only part of the batch. However, this is still optional and only needed for things like softmax or NCE loss. Note: If you later switch to ddp or some other mode, this will still be called so that you don't have to change your code.  code-block python  pseudocode sub_batches = split_batches_for_dp(batch) step_output = [validation_step(sub_batch) for sub_batch in sub_batches] validation_step_end(step_output) Args: step_output: What you return in :meth: validation_step for each batch part. Return: None or anything  code-block python  WITHOUT validation_step_end  if used in DP, this batch is 1/num_gpus large def validation_step(self, batch, batch_idx):  batch is 1/num_gpus big x, y = batch out = self.encoder(x) loss = self.softmax(out) loss = nce_loss(loss) self.log(\"val_loss\", loss)          with validation_step_end to do softmax over the full batch def validation_step(self, batch, batch_idx):  batch is 1/num_gpus big x, y = batch out = self(x) return out def validation_step_end(self, val_step_outputs): for out in val_step_outputs:  . See Also: See the :ref: Multi GPU Training   guide for more details.",
"func":1
},
{
"ref":"heyvi.recognition.CAP_AD.validation_epoch_end",
"url":1,
"doc":"Called at the end of the validation epoch with the outputs of all validation steps.  code-block python  the pseudocode for these calls val_outs = [] for val_batch in val_data: out = validation_step(val_batch) val_outs.append(out) validation_epoch_end(val_outs) Args: outputs: List of outputs you defined in :meth: validation_step , or if there are multiple dataloaders, a list containing a list of outputs for each dataloader. Return: None Note: If you didn't define a :meth: validation_step , this won't be called. Examples: With a single dataloader:  code-block python def validation_epoch_end(self, val_step_outputs): for out in val_step_outputs:  . With multiple dataloaders,  outputs will be a list of lists. The outer list contains one entry per dataloader, while the inner list contains the individual outputs of each validation step for that dataloader.  code-block python def validation_epoch_end(self, outputs): for dataloader_output_result in outputs: dataloader_outs = dataloader_output_result.dataloader_i_outputs self.log(\"final_metric\", final_value)",
"func":1
},
{
"ref":"heyvi.model",
"url":2,
"doc":""
},
{
"ref":"heyvi.model.face",
"url":3,
"doc":""
},
{
"ref":"heyvi.model.face.recognition",
"url":4,
"doc":""
},
{
"ref":"heyvi.model.face.recognition.convert_resnet101v4_image",
"url":4,
"doc":"Convert an RGB byte image to a FloatTensor suitable for processing with the network. This function assumes the image has already been resized, cropped, jittered, etc.",
"func":1
},
{
"ref":"heyvi.model.face.recognition.unconvert_resnet101v4_image",
"url":4,
"doc":"Convert a FloatTensor to an RGB byte Image",
"func":1
},
{
"ref":"heyvi.model.face.recognition.conv3x3",
"url":4,
"doc":"3x3 convolution with padding",
"func":1
},
{
"ref":"heyvi.model.face.recognition.BasicBlock",
"url":4,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.recognition.BasicBlock.expansion",
"url":4,
"doc":""
},
{
"ref":"heyvi.model.face.recognition.BasicBlock.forward",
"url":4,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.face.recognition.Bottleneck",
"url":4,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.recognition.Bottleneck.expansion",
"url":4,
"doc":""
},
{
"ref":"heyvi.model.face.recognition.Bottleneck.forward",
"url":4,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.face.recognition.ConcatChannels",
"url":4,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.recognition.ConcatChannels.forward",
"url":4,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.face.recognition.Multiply",
"url":4,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.recognition.Multiply.forward",
"url":4,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.face.recognition.ResNet",
"url":4,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.recognition.ResNet.forward",
"url":4,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.face.recognition.resnet101v6",
"url":4,
"doc":"Construct resnet-101v6 model",
"func":1
},
{
"ref":"heyvi.model.face.faster_rcnn",
"url":5,
"doc":""
},
{
"ref":"heyvi.model.face.faster_rcnn.RpnLayers",
"url":5,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.faster_rcnn.RpnLayers.forward",
"url":5,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.face.faster_rcnn.BottomLayers",
"url":5,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.faster_rcnn.BottomLayers.forward",
"url":5,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.face.faster_rcnn.TopLayers",
"url":5,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.faster_rcnn.TopLayers.forward",
"url":5,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.face.faster_rcnn.FasterRCNN",
"url":5,
"doc":"PyTorch-1.3 model conversion of ResNet-101_faster_rcnn_ohem_iter_20000.caffemodel, leveraging MMDNN conversion tools Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.faster_rcnn.FasterRCNN_MMDNN",
"url":5,
"doc":"PyTorch-1.3 model conversion of ResNet-101_faster_rcnn_ohem_iter_20000.caffemodel, leveraging MMDNN conversion tools Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.faster_rcnn.conversion",
"url":5,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.face.detection",
"url":6,
"doc":""
},
{
"ref":"heyvi.model.face.detection.log_info",
"url":6,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.face.detection.FaceRCNN",
"url":6,
"doc":"Wrapper for PyTorch RCNN detector"
},
{
"ref":"heyvi.model.face.detection.FaceRCNN.dets_to_scene",
"url":6,
"doc":"Convert detections returned from this object to a vipy.image.Scene object",
"func":1
},
{
"ref":"heyvi.model.face.detection.FaceRCNN.detect",
"url":6,
"doc":"Run detection on a numpy image, with specified padding and min size",
"func":1
},
{
"ref":"heyvi.model.face.detection.FaceRCNN.select_from_rotated",
"url":6,
"doc":"Given that we tried rotating the image, select the best rotation to use",
"func":1
},
{
"ref":"heyvi.model.face.detection.FaceRCNN.im_detect",
"url":6,
"doc":"Detect object classes in an image given object proposals. Arguments: net (pytorch): Fast R-CNN network to use im (ndarray): color image to test (in BGR order, as (H, W, C) boxes (ndarray): R x 4 array of object proposals or None (for RPN) Returns: scores (ndarray): R x K array of object class scores (K includes background as object category 0) boxes (ndarray): R x (4 K) array of predicted bounding boxes",
"func":1
},
{
"ref":"heyvi.model.face.detection.FaceRCNN.bbox_transform",
"url":6,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.face.detection.FaceRCNN.bbox_transform_inv",
"url":6,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.face.detection.FaceRCNN.clip_boxes",
"url":6,
"doc":"Clip boxes to image boundaries.",
"func":1
},
{
"ref":"heyvi.model.yolov3",
"url":7,
"doc":""
},
{
"ref":"heyvi.model.yolov3.network",
"url":8,
"doc":""
},
{
"ref":"heyvi.model.yolov3.network.create_modules",
"url":8,
"doc":"Constructs module list of layer blocks from module configuration in module_defs",
"func":1
},
{
"ref":"heyvi.model.yolov3.network.Upsample",
"url":8,
"doc":"nn.Upsample is deprecated Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov3.network.Upsample.forward",
"url":8,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov3.network.EmptyLayer",
"url":8,
"doc":"Placeholder for 'route' and 'shortcut' layers Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov3.network.YOLOLayer",
"url":8,
"doc":"Detection layer Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov3.network.YOLOLayer.compute_grid_offsets",
"url":8,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov3.network.YOLOLayer.forward",
"url":8,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov3.network.Darknet",
"url":8,
"doc":"YOLOv3 object detection model Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov3.network.Darknet.forward",
"url":8,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov3.network.Darknet.load_darknet_weights",
"url":8,
"doc":"Parses and loads the weights stored in 'weights_path'",
"func":1
},
{
"ref":"heyvi.model.yolov3.network.Darknet.save_darknet_weights",
"url":8,
"doc":"@:param path - path of the new weights file @:param cutoff - save layers between 0 and cutoff (cutoff = -1 -> all are saved)",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils",
"url":9,
"doc":""
},
{
"ref":"heyvi.model.yolov3.utils.parse_config",
"url":10,
"doc":""
},
{
"ref":"heyvi.model.yolov3.utils.parse_config.parse_model_config",
"url":10,
"doc":"Parses the yolo-v3 layer configuration file and returns module definitions",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.parse_config.parse_data_config",
"url":10,
"doc":"Parses the data configuration file",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils",
"url":11,
"doc":""
},
{
"ref":"heyvi.model.yolov3.utils.utils.to_cpu",
"url":11,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.load_classes",
"url":11,
"doc":"Loads class labels at 'path'",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.weights_init_normal",
"url":11,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.rescale_boxes",
"url":11,
"doc":"Rescales bounding boxes to the original shape",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.xywh2xyxy",
"url":11,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.ap_per_class",
"url":11,
"doc":"Compute the average precision, given the recall and precision curves. Source: https: github.com/rafaelpadilla/Object-Detection-Metrics.  Arguments tp: True positives (list). conf: Objectness value from 0-1 (list). pred_cls: Predicted object classes (list). target_cls: True object classes (list).  Returns The average precision as computed in py-faster-rcnn.",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.compute_ap",
"url":11,
"doc":"Compute the average precision, given the recall and precision curves. Code originally from https: github.com/rbgirshick/py-faster-rcnn.  Arguments recall: The recall curve (list). precision: The precision curve (list).  Returns The average precision as computed in py-faster-rcnn.",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.get_batch_statistics",
"url":11,
"doc":"Compute true positives, predicted scores and predicted labels per sample",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.bbox_wh_iou",
"url":11,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.bbox_iou",
"url":11,
"doc":"Returns the IoU of two bounding boxes",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.non_max_suppression",
"url":11,
"doc":"Removes detections with lower object confidence score than 'conf_thres' and performs Non-Maximum Suppression to further filter detections. Returns detections with shape: (x1, y1, x2, y2, object_conf, class_score, class_pred)",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.build_targets",
"url":11,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5",
"url":12,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils",
"url":13,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.autoanchor",
"url":14,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.autoanchor.check_anchor_order",
"url":14,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.autoanchor.check_anchors",
"url":14,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.autoanchor.kmean_anchors",
"url":14,
"doc":"Creates kmeans-evolved anchors from training dataset Arguments: path: path to dataset  .yaml, or a loaded dataset n: number of anchors img_size: image size used for training thr: anchor-label wh ratio threshold hyperparameter hyp['anchor_t'] used for training, default=4.0 gen: generations to evolve anchors using genetic algorithm verbose: print all results Return: k: kmeans evolved anchors Usage: from utils.autoanchor import  ; _ = kmean_anchors()",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.activations",
"url":15,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.activations.Swish",
"url":15,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.utils.activations.Swish.forward",
"url":15,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.activations.Hardswish",
"url":15,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.utils.activations.Hardswish.forward",
"url":15,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.activations.MemoryEfficientSwish",
"url":15,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.utils.activations.MemoryEfficientSwish.F",
"url":15,
"doc":"Base class to create custom  autograd.Function To create a custom  autograd.Function , subclass this class and implement the :meth: forward and :meth: backward static methods. Then, to use your custom op in the forward pass, call the class method  apply . Do not call :meth: forward directly. To ensure correctness and best performance, make sure you are calling the correct methods on  ctx and validating your backward function using :func: torch.autograd.gradcheck . See :ref: extending-autograd for more details on how to use this class. Examples >>>  xdoctest: +REQUIRES(env:TORCH_DOCTEST_AUTOGRAD) >>> class Exp(Function): >>> @staticmethod >>> def forward(ctx, i): >>> result = i.exp() >>> ctx.save_for_backward(result) >>> return result >>> >>> @staticmethod >>> def backward(ctx, grad_output): >>> result, = ctx.saved_tensors >>> return grad_output  result >>> >>>  Use it by calling the apply method: >>>  xdoctest: +SKIP >>> output = Exp.apply(input)"
},
{
"ref":"heyvi.model.yolov5.utils.activations.MemoryEfficientSwish.forward",
"url":15,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.activations.Mish",
"url":15,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.utils.activations.Mish.forward",
"url":15,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.activations.MemoryEfficientMish",
"url":15,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.utils.activations.MemoryEfficientMish.F",
"url":15,
"doc":"Base class to create custom  autograd.Function To create a custom  autograd.Function , subclass this class and implement the :meth: forward and :meth: backward static methods. Then, to use your custom op in the forward pass, call the class method  apply . Do not call :meth: forward directly. To ensure correctness and best performance, make sure you are calling the correct methods on  ctx and validating your backward function using :func: torch.autograd.gradcheck . See :ref: extending-autograd for more details on how to use this class. Examples >>>  xdoctest: +REQUIRES(env:TORCH_DOCTEST_AUTOGRAD) >>> class Exp(Function): >>> @staticmethod >>> def forward(ctx, i): >>> result = i.exp() >>> ctx.save_for_backward(result) >>> return result >>> >>> @staticmethod >>> def backward(ctx, grad_output): >>> result, = ctx.saved_tensors >>> return grad_output  result >>> >>>  Use it by calling the apply method: >>>  xdoctest: +SKIP >>> output = Exp.apply(input)"
},
{
"ref":"heyvi.model.yolov5.utils.activations.MemoryEfficientMish.forward",
"url":15,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.activations.FReLU",
"url":15,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.utils.activations.FReLU.forward",
"url":15,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.metrics",
"url":16,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.metrics.fitness",
"url":16,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.metrics.ap_per_class",
"url":16,
"doc":"Compute the average precision, given the recall and precision curves. Source: https: github.com/rafaelpadilla/Object-Detection-Metrics.  Arguments tp: True positives (nparray, nx1 or nx10). conf: Objectness value from 0-1 (nparray). pred_cls: Predicted object classes (nparray). target_cls: True object classes (nparray). plot: Plot precision-recall curve at mAP@0.5 save_dir: Plot save directory  Returns The average precision as computed in py-faster-rcnn.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.metrics.compute_ap",
"url":16,
"doc":"Compute the average precision, given the recall and precision curves. Source: https: github.com/rbgirshick/py-faster-rcnn.  Arguments recall: The recall curve (list). precision: The precision curve (list).  Returns The average precision as computed in py-faster-rcnn.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.metrics.ConfusionMatrix",
"url":16,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.metrics.ConfusionMatrix.process_batch",
"url":16,
"doc":"Return intersection-over-union (Jaccard index) of boxes. Both sets of boxes are expected to be in (x1, y1, x2, y2) format. Arguments: detections (Array[N, 6]), x1, y1, x2, y2, conf, class labels (Array[M, 5]), class, x1, y1, x2, y2 Returns: None, updates confusion matrix accordingly",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.metrics.ConfusionMatrix.matrix",
"url":16,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.metrics.ConfusionMatrix.plot",
"url":16,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.metrics.ConfusionMatrix.print",
"url":16,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.metrics.plot_pr_curve",
"url":16,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.google_utils",
"url":17,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.google_utils.gsutil_getsize",
"url":17,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.google_utils.attempt_download",
"url":17,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.google_utils.gdrive_download",
"url":17,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.google_utils.get_token",
"url":17,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.loss",
"url":18,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.loss.smooth_BCE",
"url":18,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.loss.BCEBlurWithLogitsLoss",
"url":18,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.utils.loss.BCEBlurWithLogitsLoss.forward",
"url":18,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.loss.FocalLoss",
"url":18,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.utils.loss.FocalLoss.forward",
"url":18,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.loss.QFocalLoss",
"url":18,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.utils.loss.QFocalLoss.forward",
"url":18,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.loss.compute_loss",
"url":18,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.loss.build_targets",
"url":18,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils",
"url":19,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.torch_distributed_zero_first",
"url":19,
"doc":"Decorator to make all processes in distributed training wait for each local_master to do something.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.init_torch_seeds",
"url":19,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.select_device",
"url":19,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.time_synchronized",
"url":19,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.is_parallel",
"url":19,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.intersect_dicts",
"url":19,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.initialize_weights",
"url":19,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.find_modules",
"url":19,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.sparsity",
"url":19,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.prune",
"url":19,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.fuse_conv_and_bn",
"url":19,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.model_info",
"url":19,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.load_classifier",
"url":19,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.scale_img",
"url":19,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.copy_attr",
"url":19,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.ModelEMA",
"url":19,
"doc":"Model Exponential Moving Average from https: github.com/rwightman/pytorch-image-models Keep a moving average of everything in the model state_dict (parameters and buffers). This is intended to allow functionality like https: www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage A smoothed version of the weights is necessary for some training schemes to perform well. This class is sensitive where it is initialized in the sequence of model init, GPU assignment and distributed training wrappers."
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.ModelEMA.update",
"url":19,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.ModelEMA.update_attr",
"url":19,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general",
"url":20,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.general.set_logging",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.init_seeds",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.get_latest_run",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.check_git_status",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.check_img_size",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.check_file",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.check_dataset",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.make_divisible",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.labels_to_class_weights",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.labels_to_image_weights",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.coco80_to_coco91_class",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.xyxy2xywh",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.xywh2xyxy",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.scale_coords",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.clip_coords",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.bbox_iou",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.box_iou",
"url":20,
"doc":"Return intersection-over-union (Jaccard index) of boxes. Both sets of boxes are expected to be in (x1, y1, x2, y2) format. Arguments: box1 (Tensor[N, 4]) box2 (Tensor[M, 4]) Returns: iou (Tensor[N, M]): the NxM matrix containing the pairwise IoU values for every element in boxes1 and boxes2",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.wh_iou",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.non_max_suppression",
"url":20,
"doc":"Performs Non-Maximum Suppression (NMS) on inference results Returns: detections with shape: nx6 (x1, y1, x2, y2, conf, cls)",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.strip_optimizer",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.print_mutation",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.apply_classifier",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.increment_path",
"url":20,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models",
"url":21,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.autopad",
"url":22,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.DWConv",
"url":22,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Conv",
"url":22,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.common.Conv.forward",
"url":22,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Conv.fuseforward",
"url":22,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Bottleneck",
"url":22,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.common.Bottleneck.forward",
"url":22,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.BottleneckCSP",
"url":22,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.common.BottleneckCSP.forward",
"url":22,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.SPP",
"url":22,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.common.SPP.forward",
"url":22,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Focus",
"url":22,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.common.Focus.forward",
"url":22,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Concat",
"url":22,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.common.Concat.forward",
"url":22,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.NMS",
"url":22,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.common.NMS.conf",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.NMS.iou",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.NMS.classes",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.NMS.forward",
"url":22,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Detections",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.Detections.display",
"url":22,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Detections.print",
"url":22,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Detections.show",
"url":22,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Detections.save",
"url":22,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Detections.tolist",
"url":22,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Flatten",
"url":22,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.common.Flatten.forward",
"url":22,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Classify",
"url":22,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.common.Classify.forward",
"url":22,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.yolo",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.yolo.Detect",
"url":23,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.yolo.Detect.stride",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.yolo.Detect.export",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.yolo.Detect.forward",
"url":23,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.yolo.Model",
"url":23,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.yolo.Model.forward",
"url":23,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.yolo.Model.forward_once",
"url":23,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.yolo.Model.fuse",
"url":23,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.yolo.Model.nms",
"url":23,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.yolo.Model.info",
"url":23,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.yolo.parse_model",
"url":23,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.experimental",
"url":24,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.experimental.CrossConv",
"url":24,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.experimental.CrossConv.forward",
"url":24,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.experimental.C3",
"url":24,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.experimental.C3.forward",
"url":24,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.experimental.Sum",
"url":24,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.experimental.Sum.forward",
"url":24,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.experimental.GhostConv",
"url":24,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.experimental.GhostConv.forward",
"url":24,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.experimental.GhostBottleneck",
"url":24,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.experimental.GhostBottleneck.forward",
"url":24,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.experimental.MixConv2d",
"url":24,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.experimental.MixConv2d.forward",
"url":24,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.experimental.Ensemble",
"url":24,
"doc":"Holds submodules in a list. :class: ~torch.nn.ModuleList can be indexed like a regular Python list, but modules it contains are properly registered, and will be visible by all :class: ~torch.nn.Module methods. Args: modules (iterable, optional): an iterable of modules to add Example class MyModule(nn.Module): def __init__(self): super().__init__() self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)]) def forward(self, x):  ModuleList can act as an iterable, or be indexed using ints for i, l in enumerate(self.linears): x = self.linears[i  2](x) + l(x) return x Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.experimental.Ensemble.forward",
"url":24,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.experimental.attempt_load",
"url":24,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.export",
"url":25,
"doc":"Exports a YOLOv5  .pt model to ONNX and TorchScript formats Usage: $ export PYTHONPATH=\"$PWD\"  python models/export.py  weights ./weights/yolov5s.pt  img 640  batch 1"
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch",
"url":26,
"doc":""
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet",
"url":27,
"doc":""
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.get_inplanes",
"url":27,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.conv3x3x3",
"url":27,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.conv1x1x1",
"url":27,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.BasicBlock",
"url":27,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.BasicBlock.expansion",
"url":27,
"doc":""
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.BasicBlock.forward",
"url":27,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.Bottleneck",
"url":27,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.Bottleneck.expansion",
"url":27,
"doc":""
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.Bottleneck.forward",
"url":27,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.ResNet",
"url":27,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc.  note As per the example above, an  __init__() call to the parent class must be made before assignment on the child. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.ResNet.forward",
"url":27,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.generate_model",
"url":27,
"doc":"",
"func":1
},
{
"ref":"heyvi.version",
"url":28,
"doc":""
},
{
"ref":"heyvi.version.num",
"url":28,
"doc":"Convert the version string of the form 'X.Y.Z' to an integer 100000 X + 100 Y + Z for version comparison",
"func":1
},
{
"ref":"heyvi.version.split",
"url":28,
"doc":"Split the version string 'X.Y.Z' and return tuple (int(X), int(Y), int(Z ",
"func":1
},
{
"ref":"heyvi.version.major",
"url":28,
"doc":"Return the major version number int(X) for versionstring 'X.Y.Z'",
"func":1
},
{
"ref":"heyvi.version.minor",
"url":28,
"doc":"Return the minor version number int(Y) for versionstring 'X.Y.Z'",
"func":1
},
{
"ref":"heyvi.version.release",
"url":28,
"doc":"Return the release version number int(Z) for versionstring 'X.Y.Z'",
"func":1
},
{
"ref":"heyvi.version.at_least_version",
"url":28,
"doc":"Is versionstring='X.Y.Z' at least the current version?",
"func":1
},
{
"ref":"heyvi.version.is_at_least",
"url":28,
"doc":"Synonym for at_least_version",
"func":1
},
{
"ref":"heyvi.version.is_exactly",
"url":28,
"doc":"Is the versionstring = 'X,Y.Z' exactly equal to heyvi.__version__",
"func":1
},
{
"ref":"heyvi.version.at_least_major_version",
"url":28,
"doc":"is the major version (e.g. X, for version X.Y.Z) greater than or equal to the major version integer supplied?",
"func":1
},
{
"ref":"heyvi.label",
"url":29,
"doc":""
},
{
"ref":"heyvi.label.Label",
"url":29,
"doc":""
},
{
"ref":"heyvi.label.piplabel_to_mevalabel",
"url":29,
"doc":"",
"func":1
},
{
"ref":"heyvi.label.mevalabel_to_index",
"url":29,
"doc":"",
"func":1
},
{
"ref":"heyvi.label.piplabel_to_index",
"url":29,
"doc":"",
"func":1
},
{
"ref":"heyvi.label.pip_250k_powerset",
"url":29,
"doc":"",
"func":1
},
{
"ref":"heyvi.system",
"url":30,
"doc":""
},
{
"ref":"heyvi.system.YoutubeLive",
"url":30,
"doc":"Youtube Live stream. >>> Y = heyvi.system.YoutubeLive(encoder='480p') >>> v = heyvi.sensor.rtsp() >>> Y(v) Args: encoder [str]['480p, '720p', '360p']: The encoder settings for the youtube live stream fps [float]: The framerate in frames per second of the output stream. streamkey [str]: The youtube live key (https: support.google.com/youtube/answer/9854503?hl=en), or set as envronment variable VIPY_YOUTUBE_STREAMKEY"
},
{
"ref":"heyvi.system.Recorder",
"url":30,
"doc":"Record a livestream to an output video file This will record an out streaming to the provided outfile >>> v = vipy.video.Scene(url='rtsp:  .', framerate=30) >>> R = Recorder('/tmp/out.mp4', framerate=5) >>> R(v, seconds=60 60) To buffer to memory, you do not need this recorder, use (for small durations): >>> v = v.duration(seconds=3).load().saveas('/tmp/out.mp4') This will record three seconds from the provided RTSP stream and save in the usual way to the output file To record frame by frame: >>> v = vipy.video.RandomScene() >>> with Recorder('out.mp4') as r: >>> for im in v: >>> r(im.annotate().rgb(  write individual frames from video v"
},
{
"ref":"heyvi.system.Tracker",
"url":30,
"doc":"heyvi.system.Tracker() class. Run a video object tracker on a video or live stream. To run on a livestream:   v = heyvi.sensor.rtsp() T = heyvi.system.Tracker() with heyvi.system.YoutubeLive(fps=5, encoder='480p') as s: T(v, frame_callback=lambda im: s(im.pixelize().annotate(fontsize=15, timestamp=heyvi.util.timestamp(), timestampoffset=(6,10 ), minconf=0.5)   To run on an input file as a batch:   v = vipy.video.Scene(filename=/path/to/infile.mp4', framerate=5) T = heyvi.system.Tracker() v_tracked = T(v) v_tracked.annotate('annotation.mp4')   To stream tracks computed per frame   vi = vipy.video.Scene(filename=/path/to/infile.mp4', framerate=5) for (f,vo) in enumerate(T.stream(vi : print(vo)  tracking result at frame f   To stream tracks computed per frame, along with pixels for current frame   vi = vipy.video.Scene(filename=/path/to/infile.mp4', framerate=5) for (f,(im,vo in enumerate(zip(vi, T.stream(vi ) print(vo)  tracking result at frame f print(im)   vipy.image.Image with pixels available as im.numpy()   To stream tracks computed per frame, along with the most recent video clip of length 16:   vi = vipy.video.Scene(filename=/path/to/infile.mp4', framerate=5) for (f,(vc,vo in enumerate(zip(vi.stream().clip(16), T.stream(vi ) print(vo)  tracking result at frame f print(vc)   vipy.video.Scene with pixels for clips of length 16   For additional use cases for streaming batches, clips, frames, delays see the [vipy documentation](https: visym.github.io/vipy) Returns:  vipy.video.Scene objects with tracks corresponding to objects in  heyvi.detection.MultiscaleVideoTracker.classlist . Object tracks are \"person\", \"vehicle\", \"bicycle\"."
},
{
"ref":"heyvi.system.Tracker.stream",
"url":30,
"doc":"Tracking iterator of input video",
"func":1
},
{
"ref":"heyvi.system.Actev21",
"url":30,
"doc":"heyvi.system.Actev21() class Real time activity detection for the 37 MEVA (https: mevadata.org) activity classes >>> v = heyvi.sensor.rtsp().framerate(5) >>> S = heyvi.system.Actev21() >>> with heyvi.system.YoutubeLive(fps=5, encoder='480p') as s: >>> S(v, frame_callback=lambda im, imraw, v: s(im), minconf=0.2)"
},
{
"ref":"heyvi.system.Actev21.annotate",
"url":30,
"doc":"",
"func":1
},
{
"ref":"heyvi.system.CAP",
"url":30,
"doc":"heyvi.system.CAP() class Real time activity detection for the 512 CAP (https: visym.github.io.cap) activity classes"
},
{
"ref":"heyvi.system.CAP.annotate",
"url":30,
"doc":"",
"func":1
},
{
"ref":"heyvi.system.CAP.detect",
"url":30,
"doc":"",
"func":1
},
{
"ref":"heyvi.system.CAP.classify",
"url":30,
"doc":"",
"func":1
},
{
"ref":"heyvi.util",
"url":31,
"doc":""
},
{
"ref":"heyvi.util.timestamp",
"url":31,
"doc":"Datetime stamp in eastern timezone with microsecond resolution",
"func":1
},
{
"ref":"heyvi.sensor",
"url":32,
"doc":""
},
{
"ref":"heyvi.sensor.rtsp",
"url":32,
"doc":"Return an RTSP camera. >>> v = heyvi.sensor.rtsp() >>> im = v.preview().show().saveas('out.jpg') >>> for im in v: >>> print(im)  live stream >>> print(im.numpy(  of numpy frames Args: url: [str] The URL for the rtsp camera, must start with 'rtsp: ' fps: [float] The framerate of the returned camera, can also be set after Env: VIPY_RTSP_URL: If this environment variable is set, use this as the URL that contains integrated credentials",
"func":1
},
{
"ref":"heyvi.sensor.camera",
"url":32,
"doc":"Return RSTP camera with index n in cameralist, or the default RTSP camera if None",
"func":1
},
{
"ref":"heyvi.sensor.cameralist",
"url":32,
"doc":"Return all online RTSP cameras set up on the current network. This requires setting environment variables: VIPY_RTSP_URL_0='rtsp: user:passwd@ip.addr.0' VIPY_RTSP_URL_1='rtsp: user:passwd@ip.addr.1' VIPY_RTSP_URL_2='rtsp: user:passwd@ip.addr.2' Args: online: [bool]: If True, return only those cameras that are online. If a camera is offline return None in that camera index. If false, return all cameras specified by the environment variables.",
"func":1
},
{
"ref":"heyvi.detection",
"url":33,
"doc":""
},
{
"ref":"heyvi.detection.TorchNet",
"url":33,
"doc":"Generic Torch Convolutional Network wrapper. This is useful for parallelization and managing hardware resources."
},
{
"ref":"heyvi.detection.TorchNet.gpu",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.TorchNet.cpu",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.TorchNet.iscpu",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.TorchNet.isgpu",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.TorchNet.batchsize",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.FaceDetector",
"url":33,
"doc":"Faster R-CNN based face detector"
},
{
"ref":"heyvi.detection.FaceDetector.batchsize",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.Yolov5",
"url":33,
"doc":"Yolov5 based object detector >>> d = heyvi.detection.Detector() >>> d(vipy.image.vehicles( .show()"
},
{
"ref":"heyvi.detection.Yolov5.classlist",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.Yolov3",
"url":33,
"doc":"Yolov3 based object detector >>> d = heyvi.detection.Detector() >>> d(vipy.image.vehicles( .show()"
},
{
"ref":"heyvi.detection.Yolov3.classlist",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.ObjectDetector",
"url":33,
"doc":"Default object detector"
},
{
"ref":"heyvi.detection.MultiscaleObjectDetector",
"url":33,
"doc":"MultiscaleObjectDetector() class - Given a list of images, break each one into a set of overlapping tiles, call ObjectDetector() on each, then recombine detections based on overlap"
},
{
"ref":"heyvi.detection.VideoDetector",
"url":33,
"doc":"Iterate ObjectDetector() over each frame of video, yielding the detected frame"
},
{
"ref":"heyvi.detection.MultiscaleVideoDetector",
"url":33,
"doc":"MultiscaleObjectDetector() class - Given a list of images, break each one into a set of overlapping tiles, call ObjectDetector() on each, then recombine detections based on overlap"
},
{
"ref":"heyvi.detection.VideoTracker",
"url":33,
"doc":"Default object detector"
},
{
"ref":"heyvi.detection.VideoTracker.track",
"url":33,
"doc":"Batch tracking",
"func":1
},
{
"ref":"heyvi.detection.FaceTracker",
"url":33,
"doc":"Faster R-CNN based face detector"
},
{
"ref":"heyvi.detection.FaceTracker.track",
"url":33,
"doc":"Batch tracking",
"func":1
},
{
"ref":"heyvi.detection.MultiscaleVideoTracker",
"url":33,
"doc":"MultiscaleVideoTracker() class Args: minconf: [float]: The minimum confidence of an object detection to be considered for tracking miniou: [float]: The minimum IoU of an object detection with a track to be considered for assignment maxhistory: [int]: The maximum frame history lookback for assignment of a detection with a broken track smoothing: [str]: Unused objects: [list]: The list of allowable objects for tracking as supported by  heyvi.detection.MultiscaleObjectDetector.classlist . trackconf: [float]: The minimum confidence of an unassigned detection to spawn a new track verbose: [bool]: Logging verbosity gpu: [list]: List of GPU indexes to use batchsize: [int]: The GPU batchsize weightfile: [str]: The modelfile for the object detector overlapfrac: [int]: FIXME, this is a legacy parameter detbatchsize: [int]: The detection batchsize per image gate: [int]: The maximum distance in pixels around a detection to search for candidate tracks"
},
{
"ref":"heyvi.detection.MultiscaleVideoTracker.stream",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.MultiscaleVideoTracker.track",
"url":33,
"doc":"Batch tracking",
"func":1
},
{
"ref":"heyvi.detection.WeakAnnotationTracker",
"url":33,
"doc":"heyvi.detection.WeakAnnotationTracker() Given a weak annotation of an object bounding box from a human annotator, refine this weak annotation into a tight box using object detection proposals and tracking. Approach: - The input video should have weak tracks provided by live annotators with class names that intersect  heyvi.detection.MultiscaleVideoTracker.classlist . - Weak annotations are too loose, too tight, or poorly centered boxes provided by live annotators while recording. - This function runs a low confidence object detector and rescores object detection confidences based on overlap with the proposal. - Detections that maximally overlap the proposal with high detection confidence are proritized for tracking. - The tracker compbines these rescored detections as in the VideoTracker. - When done, each proposal is assigned to one track, and track IDs and activity IDs are mappped accordingly. - Activities that no longer overlap the actor track are removed - The tracker is run at a lower framerate (5Hz) then tracks are resampled to the input framerate Usage: Batch annotation tracker:   T = heyvi.detection.WeakAnnotationTracker() v = vipy.video.Scene( .)  contains weak annotations vt = T.track(v)  refined proposals vm = vt.combine(v.trackmap(lambda t: t.category('weak annotation' )   Streaming annotation tracker:   T = heyvi.detection.WeakAnnotationTracker() v = vipy.video.Scene( .)  contains weak annotations for vt in T(v): print(vt)    note - The video vt will be a clone of v such that each track in vt will be a refined track of a track in v. - All track and activities IDs are mapped appropriately from the input video. - The combined video vm has both the weak annotation and the refined tracks. - The tracker is run at a lower framerate (5Hz) then tracks are resampled to the input framerate. This is useful for linear track interpolation. - The tracker does not handle synonyms or capitalization differences like 'motorcycle' vs. 'Motorbike'. Be sure that the weak annotation input video overlaps with  heyvi.detection.MultiscaleVideoTracker.classlist "
},
{
"ref":"heyvi.detection.WeakAnnotationTracker.track",
"url":33,
"doc":"Batch tracking",
"func":1
},
{
"ref":"heyvi.detection.WeakAnnotationFaceTracker",
"url":33,
"doc":"heyvi.detection.WeakAnnotationFaceTracker() Given a weak annotation of an person, face or head bounding box from a human annotator, refine this weak annotation into a tight box around the face using object detection proposals and tracking. Approach: - The input video should have weak tracks provided by live annotators with class names that are in ['person', 'face', 'head'] - Weak annotations are too loose, too tight, or poorly centered boxes provided by live annotators while recording. - This function runs a low confidence face detector and rescores face detection confidences based on overlap with the proposal. - Detections that maximally overlap the proposal with high detection confidence are proritized for track assignment. - The tracker compbines these rescored detections as in the VideoTracker. - When done, each track is assigned to a proposal. - The tracker is run at a lower framerate (5Hz) then tracks are resampled to the input framerate See also:  heyvi.detection.WeakAnnotationTracker "
},
{
"ref":"heyvi.detection.WeakAnnotationFaceTracker.track",
"url":33,
"doc":"Batch tracking",
"func":1
},
{
"ref":"heyvi.detection.ActorAssociation",
"url":33,
"doc":"heyvi.detection.VideoAssociation() class Select the best object track of the target class associated with the primary actor class by gated spatial IOU and distance. Add the best object track to the scene and associate with all activities performed by the primary actor.  warning This is scheduled for deprecation, as the gating is unreliable. This should be replaced by the WeakAnnotationTracker for a target class."
},
{
"ref":"heyvi.detection.ActorAssociation.isallowable",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.ActorAssociation.track",
"url":33,
"doc":"Batch tracking",
"func":1
}
]