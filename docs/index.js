URLS=[
"heyvi/index.html",
"heyvi/sensor.html",
"heyvi/system.html",
"heyvi/model/index.html",
"heyvi/model/ResNets_3D_PyTorch/index.html",
"heyvi/model/ResNets_3D_PyTorch/resnet.html",
"heyvi/model/face/index.html",
"heyvi/model/face/recognition.html",
"heyvi/model/face/faster_rcnn.html",
"heyvi/model/face/detection.html",
"heyvi/model/yolov5/index.html",
"heyvi/model/yolov5/utils/index.html",
"heyvi/model/yolov5/utils/torch_utils.html",
"heyvi/model/yolov5/utils/general.html",
"heyvi/model/yolov5/utils/activations.html",
"heyvi/model/yolov5/utils/metrics.html",
"heyvi/model/yolov5/utils/google_utils.html",
"heyvi/model/yolov5/utils/autoanchor.html",
"heyvi/model/yolov5/utils/loss.html",
"heyvi/model/yolov5/models/index.html",
"heyvi/model/yolov5/models/export.html",
"heyvi/model/yolov5/models/yolo.html",
"heyvi/model/yolov5/models/experimental.html",
"heyvi/model/yolov5/models/common.html",
"heyvi/model/yolov3/index.html",
"heyvi/model/yolov3/utils/index.html",
"heyvi/model/yolov3/utils/parse_config.html",
"heyvi/model/yolov3/utils/utils.html",
"heyvi/model/yolov3/network.html",
"heyvi/label.html",
"heyvi/version.html",
"heyvi/recognition.html",
"heyvi/util.html",
"heyvi/detection.html"
];
INDEX=[
{
"ref":"heyvi",
"url":0,
"doc":" \"Hey Vi!\" HEYVI is a python package for visual AI that provides systems and trained models for activity detection and object tracking in videos. HEYVI provides:  Real time activity detection of the [MEVA activity classes](https: mevadata.org)  Real time visual object tracking in long duration videos  Live streaming of annotated videos to youtube live  Visual AI from RTSP cameras  Environment variables The following environment varibles may be set by the client: VIPY_RTSP_URL='rtsp: user@password:127.0.0.1' VIPY_RTSP_URL_0='rtsp: user@password:127.0.0.1' VIPY_RTSP_URL_1='rtsp: user@password:127.0.0.2' VIPY_YOUTUBE_STREAMKEY='xxxx-xxxx-xxxx-xxxx-xxxx' VIPY_CACHE='/home/username/.vipy' Where the environment variables VIPY_RTSP_URL_N are the list of cameras that are specified in  heyvi.sensors.cameralist , and VIPY_RTSP_URL refers to the default RTSP camera in  heyvi.sensor.rtsp .  Versioning To determine what heyvi version you are running you can use: >>> heyvi.__version__ >>> heyvi.version.is_at_least('0.0.6')  Contact Visym Labs  "
},
{
"ref":"heyvi.sensor",
"url":1,
"doc":""
},
{
"ref":"heyvi.sensor.rtsp",
"url":1,
"doc":"Return an RTSP camera. >>> v = heyvi.sensor.rtsp() >>> im = v.preview().show().saveas('out.jpg') >>> for im in v: >>> print(im)  live stream >>> print(im.numpy(  of numpy frames Args: url: [str] The URL for the rtsp camera, must start with 'rtsp: ' fps: [float] The framerate of the returned camera, can also be set after Env: VIPY_RTSP_URL: If this environment variable is set, use this as the URL that contains integrated credentials",
"func":1
},
{
"ref":"heyvi.sensor.cameralist",
"url":1,
"doc":"Return all online RTSP cameras set up on the current network. This requires setting environment variables: VIPY_RTSP_URL_0='rtsp: user:passwd@ip.addr.0' VIPY_RTSP_URL_1='rtsp: user:passwd@ip.addr.1' VIPY_RTSP_URL_2='rtsp: user:passwd@ip.addr.2' Args: online [bool]: If True, return only those cameras that are online. If a camera is offline return None in that camera index. If false, return all cameras",
"func":1
},
{
"ref":"heyvi.system",
"url":2,
"doc":""
},
{
"ref":"heyvi.system.YoutubeLive",
"url":2,
"doc":"Youtube Live stream. >>> Y = heyvi.system.YoutubeLive(encoder='480p') >>> v = heyvi.sensor.rtsp() >>> Y(v) Args: encoder [str]['480p, '720p', '360p']: The encoder settings for the youtube live stream fps [float]: The framerate in frames per second of the output stream. streamkey [str]: The youtube live key (https: support.google.com/youtube/answer/9854503?hl=en), or set as envronment variable VIPY_YOUTUBE_STREAMKEY"
},
{
"ref":"heyvi.system.Recorder",
"url":2,
"doc":"Record a livestream to an output video file This will record an out streaming to the provided outfile >>> v = vipy.video.Scene(url='rtsp:  .', framerate=30) >>> R = Recorder('/tmp/out.mp4', framerate=5) >>> R(v, seconds=60 60) To buffer to memory, you do not need this recorder, use (for small durations): >>> v = v.duration(seconds=3).load().saveas('/tmp/out.mp4') This will record three seconds from the provided RTSP stream and save in the usual way to the output file To record frame by frame: >>> v = vipy.video.RandomScene() >>> with Recorder('out.mp4') as r: >>> for im in v: >>> r(im.annotate().rgb(  write individual frames from video v"
},
{
"ref":"heyvi.system.Tracker",
"url":2,
"doc":"heyvi.system.Tracker class >>> v = heyvi.sensor.rtsp() >>> T = heyvi.system.Tracker() >>> with heyvi.system.YoutubeLive(fps=5, encoder='480p') as s: >>> T(v, frame_callback=lambda im: s(im.pixelize().annotate(fontsize=15, timestamp=heyvi.util.timestamp(), timestampoffset=(6,10 ), minconf=0.5)"
},
{
"ref":"heyvi.system.Actev21",
"url":2,
"doc":"heyvi.system.Actev21 class Real time activity detection for the 37 MEVA (https: mevadata.org) activity classes >>> v = heyvi.sensor.rtsp().framerate(5) >>> S = heyvi.system.Actev21() >>> with heyvi.system.YoutubeLive(fps=5, encoder='480p') as s: >>> S(v, frame_callback=lambda im, imraw, v: s(im), minconf=0.2)"
},
{
"ref":"heyvi.system.Actev21.annotate",
"url":2,
"doc":"",
"func":1
},
{
"ref":"heyvi.model",
"url":3,
"doc":""
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch",
"url":4,
"doc":""
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet",
"url":5,
"doc":""
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.get_inplanes",
"url":5,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.conv3x3x3",
"url":5,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.conv1x1x1",
"url":5,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.BasicBlock",
"url":5,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.BasicBlock.dump_patches",
"url":5,
"doc":""
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.BasicBlock.training",
"url":5,
"doc":""
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.BasicBlock.expansion",
"url":5,
"doc":""
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.BasicBlock.forward",
"url":5,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.Bottleneck",
"url":5,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.Bottleneck.dump_patches",
"url":5,
"doc":""
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.Bottleneck.training",
"url":5,
"doc":""
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.Bottleneck.expansion",
"url":5,
"doc":""
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.Bottleneck.forward",
"url":5,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.ResNet",
"url":5,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.ResNet.dump_patches",
"url":5,
"doc":""
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.ResNet.training",
"url":5,
"doc":""
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.ResNet.forward",
"url":5,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.ResNets_3D_PyTorch.resnet.generate_model",
"url":5,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.face",
"url":6,
"doc":""
},
{
"ref":"heyvi.model.face.recognition",
"url":7,
"doc":""
},
{
"ref":"heyvi.model.face.recognition.convert_resnet101v4_image",
"url":7,
"doc":"Convert an RGB byte image to a FloatTensor suitable for processing with the network. This function assumes the image has already been resized, cropped, jittered, etc.",
"func":1
},
{
"ref":"heyvi.model.face.recognition.unconvert_resnet101v4_image",
"url":7,
"doc":"Convert a FloatTensor to an RGB byte Image",
"func":1
},
{
"ref":"heyvi.model.face.recognition.conv3x3",
"url":7,
"doc":"3x3 convolution with padding",
"func":1
},
{
"ref":"heyvi.model.face.recognition.BasicBlock",
"url":7,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.recognition.BasicBlock.dump_patches",
"url":7,
"doc":""
},
{
"ref":"heyvi.model.face.recognition.BasicBlock.training",
"url":7,
"doc":""
},
{
"ref":"heyvi.model.face.recognition.BasicBlock.expansion",
"url":7,
"doc":""
},
{
"ref":"heyvi.model.face.recognition.BasicBlock.forward",
"url":7,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.face.recognition.Bottleneck",
"url":7,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.recognition.Bottleneck.dump_patches",
"url":7,
"doc":""
},
{
"ref":"heyvi.model.face.recognition.Bottleneck.training",
"url":7,
"doc":""
},
{
"ref":"heyvi.model.face.recognition.Bottleneck.expansion",
"url":7,
"doc":""
},
{
"ref":"heyvi.model.face.recognition.Bottleneck.forward",
"url":7,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.face.recognition.ConcatChannels",
"url":7,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.recognition.ConcatChannels.dump_patches",
"url":7,
"doc":""
},
{
"ref":"heyvi.model.face.recognition.ConcatChannels.training",
"url":7,
"doc":""
},
{
"ref":"heyvi.model.face.recognition.ConcatChannels.forward",
"url":7,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.face.recognition.Multiply",
"url":7,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.recognition.Multiply.dump_patches",
"url":7,
"doc":""
},
{
"ref":"heyvi.model.face.recognition.Multiply.training",
"url":7,
"doc":""
},
{
"ref":"heyvi.model.face.recognition.Multiply.forward",
"url":7,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.face.recognition.ResNet",
"url":7,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.recognition.ResNet.dump_patches",
"url":7,
"doc":""
},
{
"ref":"heyvi.model.face.recognition.ResNet.training",
"url":7,
"doc":""
},
{
"ref":"heyvi.model.face.recognition.ResNet.forward",
"url":7,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.face.recognition.resnet101v6",
"url":7,
"doc":"Construct resnet-101v6 model",
"func":1
},
{
"ref":"heyvi.model.face.faster_rcnn",
"url":8,
"doc":""
},
{
"ref":"heyvi.model.face.faster_rcnn.RpnLayers",
"url":8,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.faster_rcnn.RpnLayers.dump_patches",
"url":8,
"doc":""
},
{
"ref":"heyvi.model.face.faster_rcnn.RpnLayers.training",
"url":8,
"doc":""
},
{
"ref":"heyvi.model.face.faster_rcnn.RpnLayers.forward",
"url":8,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.face.faster_rcnn.BottomLayers",
"url":8,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.faster_rcnn.BottomLayers.dump_patches",
"url":8,
"doc":""
},
{
"ref":"heyvi.model.face.faster_rcnn.BottomLayers.training",
"url":8,
"doc":""
},
{
"ref":"heyvi.model.face.faster_rcnn.BottomLayers.forward",
"url":8,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.face.faster_rcnn.TopLayers",
"url":8,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.faster_rcnn.TopLayers.dump_patches",
"url":8,
"doc":""
},
{
"ref":"heyvi.model.face.faster_rcnn.TopLayers.training",
"url":8,
"doc":""
},
{
"ref":"heyvi.model.face.faster_rcnn.TopLayers.forward",
"url":8,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.face.faster_rcnn.FasterRCNN",
"url":8,
"doc":"PyTorch-1.3 model conversion of ResNet-101_faster_rcnn_ohem_iter_20000.caffemodel, leveraging MMDNN conversion tools Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.faster_rcnn.FasterRCNN.dump_patches",
"url":8,
"doc":""
},
{
"ref":"heyvi.model.face.faster_rcnn.FasterRCNN.training",
"url":8,
"doc":""
},
{
"ref":"heyvi.model.face.faster_rcnn.FasterRCNN.forward",
"url":8,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.face.faster_rcnn.FasterRCNN_MMDNN",
"url":8,
"doc":"PyTorch-1.3 model conversion of ResNet-101_faster_rcnn_ohem_iter_20000.caffemodel, leveraging MMDNN conversion tools Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.face.faster_rcnn.FasterRCNN_MMDNN.dump_patches",
"url":8,
"doc":""
},
{
"ref":"heyvi.model.face.faster_rcnn.FasterRCNN_MMDNN.training",
"url":8,
"doc":""
},
{
"ref":"heyvi.model.face.faster_rcnn.FasterRCNN_MMDNN.forward",
"url":8,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.face.faster_rcnn.conversion",
"url":8,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.face.detection",
"url":9,
"doc":""
},
{
"ref":"heyvi.model.face.detection.log_info",
"url":9,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.face.detection.FaceRCNN",
"url":9,
"doc":"Wrapper for PyTorch RCNN detector"
},
{
"ref":"heyvi.model.face.detection.FaceRCNN.dets_to_scene",
"url":9,
"doc":"Convert detections returned from this object to a vipy.image.Scene object",
"func":1
},
{
"ref":"heyvi.model.face.detection.FaceRCNN.detect",
"url":9,
"doc":"Run detection on a numpy image, with specified padding and min size",
"func":1
},
{
"ref":"heyvi.model.face.detection.FaceRCNN.select_from_rotated",
"url":9,
"doc":"Given that we tried rotating the image, select the best rotation to use",
"func":1
},
{
"ref":"heyvi.model.face.detection.FaceRCNN.im_detect",
"url":9,
"doc":"Detect object classes in an image given object proposals. Arguments: net (pytorch): Fast R-CNN network to use im (ndarray): color image to test (in BGR order, as (H, W, C) boxes (ndarray): R x 4 array of object proposals or None (for RPN) Returns: scores (ndarray): R x K array of object class scores (K includes background as object category 0) boxes (ndarray): R x (4 K) array of predicted bounding boxes",
"func":1
},
{
"ref":"heyvi.model.face.detection.FaceRCNN.bbox_transform",
"url":9,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.face.detection.FaceRCNN.bbox_transform_inv",
"url":9,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.face.detection.FaceRCNN.clip_boxes",
"url":9,
"doc":"Clip boxes to image boundaries.",
"func":1
},
{
"ref":"heyvi.model.yolov5",
"url":10,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils",
"url":11,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils",
"url":12,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.torch_distributed_zero_first",
"url":12,
"doc":"Decorator to make all processes in distributed training wait for each local_master to do something.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.init_torch_seeds",
"url":12,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.select_device",
"url":12,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.time_synchronized",
"url":12,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.is_parallel",
"url":12,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.intersect_dicts",
"url":12,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.initialize_weights",
"url":12,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.find_modules",
"url":12,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.sparsity",
"url":12,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.prune",
"url":12,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.fuse_conv_and_bn",
"url":12,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.model_info",
"url":12,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.load_classifier",
"url":12,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.scale_img",
"url":12,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.copy_attr",
"url":12,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.ModelEMA",
"url":12,
"doc":"Model Exponential Moving Average from https: github.com/rwightman/pytorch-image-models Keep a moving average of everything in the model state_dict (parameters and buffers). This is intended to allow functionality like https: www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage A smoothed version of the weights is necessary for some training schemes to perform well. This class is sensitive where it is initialized in the sequence of model init, GPU assignment and distributed training wrappers."
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.ModelEMA.update",
"url":12,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.torch_utils.ModelEMA.update_attr",
"url":12,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general",
"url":13,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.general.set_logging",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.init_seeds",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.get_latest_run",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.check_git_status",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.check_img_size",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.check_file",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.check_dataset",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.make_divisible",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.labels_to_class_weights",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.labels_to_image_weights",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.coco80_to_coco91_class",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.xyxy2xywh",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.xywh2xyxy",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.scale_coords",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.clip_coords",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.bbox_iou",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.box_iou",
"url":13,
"doc":"Return intersection-over-union (Jaccard index) of boxes. Both sets of boxes are expected to be in (x1, y1, x2, y2) format. Arguments: box1 (Tensor[N, 4]) box2 (Tensor[M, 4]) Returns: iou (Tensor[N, M]): the NxM matrix containing the pairwise IoU values for every element in boxes1 and boxes2",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.wh_iou",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.non_max_suppression",
"url":13,
"doc":"Performs Non-Maximum Suppression (NMS) on inference results Returns: detections with shape: nx6 (x1, y1, x2, y2, conf, cls)",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.strip_optimizer",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.print_mutation",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.apply_classifier",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.general.increment_path",
"url":13,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.activations",
"url":14,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.activations.Swish",
"url":14,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.utils.activations.Swish.dump_patches",
"url":14,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.activations.Swish.training",
"url":14,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.activations.Swish.forward",
"url":14,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.activations.Hardswish",
"url":14,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.utils.activations.Hardswish.dump_patches",
"url":14,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.activations.Hardswish.training",
"url":14,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.activations.Hardswish.forward",
"url":14,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.activations.MemoryEfficientSwish",
"url":14,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.utils.activations.MemoryEfficientSwish.dump_patches",
"url":14,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.activations.MemoryEfficientSwish.training",
"url":14,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.activations.MemoryEfficientSwish.F",
"url":14,
"doc":"Records operation history and defines formulas for differentiating ops. See the Note on extending the autograd engine for more details on how to use this class: https: pytorch.org/docs/stable/notes/extending.html extending-torch-autograd Every operation performed on :class: Tensor s creates a new function object, that performs the computation, and records that it happened. The history is retained in the form of a DAG of functions, with edges denoting data dependencies ( input  >> class Exp(Function): >>> >>> @staticmethod >>> def forward(ctx, i): >>> result = i.exp() >>> ctx.save_for_backward(result) >>> return result >>> >>> @staticmethod >>> def backward(ctx, grad_output): >>> result, = ctx.saved_tensors >>> return grad_output  result >>> >>>  Use it by calling the apply method: >>> output = Exp.apply(input)"
},
{
"ref":"heyvi.model.yolov5.utils.activations.MemoryEfficientSwish.forward",
"url":14,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.activations.Mish",
"url":14,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.utils.activations.Mish.dump_patches",
"url":14,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.activations.Mish.training",
"url":14,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.activations.Mish.forward",
"url":14,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.activations.MemoryEfficientMish",
"url":14,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.utils.activations.MemoryEfficientMish.dump_patches",
"url":14,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.activations.MemoryEfficientMish.training",
"url":14,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.activations.MemoryEfficientMish.F",
"url":14,
"doc":"Records operation history and defines formulas for differentiating ops. See the Note on extending the autograd engine for more details on how to use this class: https: pytorch.org/docs/stable/notes/extending.html extending-torch-autograd Every operation performed on :class: Tensor s creates a new function object, that performs the computation, and records that it happened. The history is retained in the form of a DAG of functions, with edges denoting data dependencies ( input  >> class Exp(Function): >>> >>> @staticmethod >>> def forward(ctx, i): >>> result = i.exp() >>> ctx.save_for_backward(result) >>> return result >>> >>> @staticmethod >>> def backward(ctx, grad_output): >>> result, = ctx.saved_tensors >>> return grad_output  result >>> >>>  Use it by calling the apply method: >>> output = Exp.apply(input)"
},
{
"ref":"heyvi.model.yolov5.utils.activations.MemoryEfficientMish.forward",
"url":14,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.activations.FReLU",
"url":14,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.utils.activations.FReLU.dump_patches",
"url":14,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.activations.FReLU.training",
"url":14,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.activations.FReLU.forward",
"url":14,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.metrics",
"url":15,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.metrics.fitness",
"url":15,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.metrics.ap_per_class",
"url":15,
"doc":"Compute the average precision, given the recall and precision curves. Source: https: github.com/rafaelpadilla/Object-Detection-Metrics.  Arguments tp: True positives (nparray, nx1 or nx10). conf: Objectness value from 0-1 (nparray). pred_cls: Predicted object classes (nparray). target_cls: True object classes (nparray). plot: Plot precision-recall curve at mAP@0.5 save_dir: Plot save directory  Returns The average precision as computed in py-faster-rcnn.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.metrics.compute_ap",
"url":15,
"doc":"Compute the average precision, given the recall and precision curves. Source: https: github.com/rbgirshick/py-faster-rcnn.  Arguments recall: The recall curve (list). precision: The precision curve (list).  Returns The average precision as computed in py-faster-rcnn.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.metrics.ConfusionMatrix",
"url":15,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.metrics.ConfusionMatrix.process_batch",
"url":15,
"doc":"Return intersection-over-union (Jaccard index) of boxes. Both sets of boxes are expected to be in (x1, y1, x2, y2) format. Arguments: detections (Array[N, 6]), x1, y1, x2, y2, conf, class labels (Array[M, 5]), class, x1, y1, x2, y2 Returns: None, updates confusion matrix accordingly",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.metrics.ConfusionMatrix.matrix",
"url":15,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.metrics.ConfusionMatrix.plot",
"url":15,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.metrics.ConfusionMatrix.print",
"url":15,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.metrics.plot_pr_curve",
"url":15,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.google_utils",
"url":16,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.google_utils.gsutil_getsize",
"url":16,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.google_utils.attempt_download",
"url":16,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.google_utils.gdrive_download",
"url":16,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.google_utils.get_token",
"url":16,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.autoanchor",
"url":17,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.autoanchor.check_anchor_order",
"url":17,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.autoanchor.check_anchors",
"url":17,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.autoanchor.kmean_anchors",
"url":17,
"doc":"Creates kmeans-evolved anchors from training dataset Arguments: path: path to dataset  .yaml, or a loaded dataset n: number of anchors img_size: image size used for training thr: anchor-label wh ratio threshold hyperparameter hyp['anchor_t'] used for training, default=4.0 gen: generations to evolve anchors using genetic algorithm verbose: print all results Return: k: kmeans evolved anchors Usage: from utils.autoanchor import  ; _ = kmean_anchors()",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.loss",
"url":18,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.loss.smooth_BCE",
"url":18,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.loss.BCEBlurWithLogitsLoss",
"url":18,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.utils.loss.BCEBlurWithLogitsLoss.dump_patches",
"url":18,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.loss.BCEBlurWithLogitsLoss.training",
"url":18,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.loss.BCEBlurWithLogitsLoss.forward",
"url":18,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.loss.FocalLoss",
"url":18,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.utils.loss.FocalLoss.dump_patches",
"url":18,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.loss.FocalLoss.training",
"url":18,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.loss.FocalLoss.forward",
"url":18,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.loss.QFocalLoss",
"url":18,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.utils.loss.QFocalLoss.dump_patches",
"url":18,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.loss.QFocalLoss.training",
"url":18,
"doc":""
},
{
"ref":"heyvi.model.yolov5.utils.loss.QFocalLoss.forward",
"url":18,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.loss.compute_loss",
"url":18,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.utils.loss.build_targets",
"url":18,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models",
"url":19,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.export",
"url":20,
"doc":"Exports a YOLOv5  .pt model to ONNX and TorchScript formats Usage: $ export PYTHONPATH=\"$PWD\"  python models/export.py  weights ./weights/yolov5s.pt  img 640  batch 1"
},
{
"ref":"heyvi.model.yolov5.models.yolo",
"url":21,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.yolo.Detect",
"url":21,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.yolo.Detect.dump_patches",
"url":21,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.yolo.Detect.training",
"url":21,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.yolo.Detect.stride",
"url":21,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.yolo.Detect.export",
"url":21,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.yolo.Detect.forward",
"url":21,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.yolo.Model",
"url":21,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.yolo.Model.dump_patches",
"url":21,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.yolo.Model.training",
"url":21,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.yolo.Model.forward",
"url":21,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.yolo.Model.forward_once",
"url":21,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.yolo.Model.fuse",
"url":21,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.yolo.Model.nms",
"url":21,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.yolo.Model.info",
"url":21,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.yolo.parse_model",
"url":21,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.experimental",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.experimental.CrossConv",
"url":22,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.experimental.CrossConv.dump_patches",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.experimental.CrossConv.training",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.experimental.CrossConv.forward",
"url":22,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.experimental.C3",
"url":22,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.experimental.C3.dump_patches",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.experimental.C3.training",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.experimental.C3.forward",
"url":22,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.experimental.Sum",
"url":22,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.experimental.Sum.dump_patches",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.experimental.Sum.training",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.experimental.Sum.forward",
"url":22,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.experimental.GhostConv",
"url":22,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.experimental.GhostConv.dump_patches",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.experimental.GhostConv.training",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.experimental.GhostConv.forward",
"url":22,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.experimental.GhostBottleneck",
"url":22,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.experimental.GhostBottleneck.dump_patches",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.experimental.GhostBottleneck.training",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.experimental.GhostBottleneck.forward",
"url":22,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.experimental.MixConv2d",
"url":22,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.experimental.MixConv2d.dump_patches",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.experimental.MixConv2d.training",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.experimental.MixConv2d.forward",
"url":22,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.experimental.Ensemble",
"url":22,
"doc":"Holds submodules in a list. :class: ~torch.nn.ModuleList can be indexed like a regular Python list, but modules it contains are properly registered, and will be visible by all :class: ~torch.nn.Module methods. Args: modules (iterable, optional): an iterable of modules to add Example class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)]) def forward(self, x):  ModuleList can act as an iterable, or be indexed using ints for i, l in enumerate(self.linears): x = self.linears[i  2](x) + l(x) return x Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.experimental.Ensemble.dump_patches",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.experimental.Ensemble.training",
"url":22,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.experimental.Ensemble.forward",
"url":22,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.experimental.attempt_load",
"url":22,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.autopad",
"url":23,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.DWConv",
"url":23,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Conv",
"url":23,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.common.Conv.dump_patches",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.Conv.training",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.Conv.forward",
"url":23,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Conv.fuseforward",
"url":23,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Bottleneck",
"url":23,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.common.Bottleneck.dump_patches",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.Bottleneck.training",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.Bottleneck.forward",
"url":23,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.BottleneckCSP",
"url":23,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.common.BottleneckCSP.dump_patches",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.BottleneckCSP.training",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.BottleneckCSP.forward",
"url":23,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.SPP",
"url":23,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.common.SPP.dump_patches",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.SPP.training",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.SPP.forward",
"url":23,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Focus",
"url":23,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.common.Focus.dump_patches",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.Focus.training",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.Focus.forward",
"url":23,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Concat",
"url":23,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.common.Concat.dump_patches",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.Concat.training",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.Concat.forward",
"url":23,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.NMS",
"url":23,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.common.NMS.dump_patches",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.NMS.training",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.NMS.conf",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.NMS.iou",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.NMS.classes",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.NMS.forward",
"url":23,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Detections",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.Detections.display",
"url":23,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Detections.print",
"url":23,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Detections.show",
"url":23,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Detections.save",
"url":23,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Detections.tolist",
"url":23,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Flatten",
"url":23,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.common.Flatten.dump_patches",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.Flatten.training",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.Flatten.forward",
"url":23,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov5.models.common.Classify",
"url":23,
"doc":"Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x return F.relu(self.conv2(x Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth: to , etc. :ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov5.models.common.Classify.dump_patches",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.Classify.training",
"url":23,
"doc":""
},
{
"ref":"heyvi.model.yolov5.models.common.Classify.forward",
"url":23,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov3",
"url":24,
"doc":""
},
{
"ref":"heyvi.model.yolov3.utils",
"url":25,
"doc":""
},
{
"ref":"heyvi.model.yolov3.utils.parse_config",
"url":26,
"doc":""
},
{
"ref":"heyvi.model.yolov3.utils.parse_config.parse_model_config",
"url":26,
"doc":"Parses the yolo-v3 layer configuration file and returns module definitions",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.parse_config.parse_data_config",
"url":26,
"doc":"Parses the data configuration file",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils",
"url":27,
"doc":""
},
{
"ref":"heyvi.model.yolov3.utils.utils.to_cpu",
"url":27,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.load_classes",
"url":27,
"doc":"Loads class labels at 'path'",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.weights_init_normal",
"url":27,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.rescale_boxes",
"url":27,
"doc":"Rescales bounding boxes to the original shape",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.xywh2xyxy",
"url":27,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.ap_per_class",
"url":27,
"doc":"Compute the average precision, given the recall and precision curves. Source: https: github.com/rafaelpadilla/Object-Detection-Metrics.  Arguments tp: True positives (list). conf: Objectness value from 0-1 (list). pred_cls: Predicted object classes (list). target_cls: True object classes (list).  Returns The average precision as computed in py-faster-rcnn.",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.compute_ap",
"url":27,
"doc":"Compute the average precision, given the recall and precision curves. Code originally from https: github.com/rbgirshick/py-faster-rcnn.  Arguments recall: The recall curve (list). precision: The precision curve (list).  Returns The average precision as computed in py-faster-rcnn.",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.get_batch_statistics",
"url":27,
"doc":"Compute true positives, predicted scores and predicted labels per sample",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.bbox_wh_iou",
"url":27,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.bbox_iou",
"url":27,
"doc":"Returns the IoU of two bounding boxes",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.non_max_suppression",
"url":27,
"doc":"Removes detections with lower object confidence score than 'conf_thres' and performs Non-Maximum Suppression to further filter detections. Returns detections with shape: (x1, y1, x2, y2, object_conf, class_score, class_pred)",
"func":1
},
{
"ref":"heyvi.model.yolov3.utils.utils.build_targets",
"url":27,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov3.network",
"url":28,
"doc":""
},
{
"ref":"heyvi.model.yolov3.network.create_modules",
"url":28,
"doc":"Constructs module list of layer blocks from module configuration in module_defs",
"func":1
},
{
"ref":"heyvi.model.yolov3.network.Upsample",
"url":28,
"doc":"nn.Upsample is deprecated Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov3.network.Upsample.dump_patches",
"url":28,
"doc":""
},
{
"ref":"heyvi.model.yolov3.network.Upsample.training",
"url":28,
"doc":""
},
{
"ref":"heyvi.model.yolov3.network.Upsample.forward",
"url":28,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov3.network.EmptyLayer",
"url":28,
"doc":"Placeholder for 'route' and 'shortcut' layers Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov3.network.EmptyLayer.dump_patches",
"url":28,
"doc":""
},
{
"ref":"heyvi.model.yolov3.network.EmptyLayer.training",
"url":28,
"doc":""
},
{
"ref":"heyvi.model.yolov3.network.EmptyLayer.forward",
"url":28,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov3.network.YOLOLayer",
"url":28,
"doc":"Detection layer Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov3.network.YOLOLayer.dump_patches",
"url":28,
"doc":""
},
{
"ref":"heyvi.model.yolov3.network.YOLOLayer.training",
"url":28,
"doc":""
},
{
"ref":"heyvi.model.yolov3.network.YOLOLayer.compute_grid_offsets",
"url":28,
"doc":"",
"func":1
},
{
"ref":"heyvi.model.yolov3.network.YOLOLayer.forward",
"url":28,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov3.network.Darknet",
"url":28,
"doc":"YOLOv3 object detection model Initializes internal Module state, shared by both nn.Module and ScriptModule."
},
{
"ref":"heyvi.model.yolov3.network.Darknet.dump_patches",
"url":28,
"doc":""
},
{
"ref":"heyvi.model.yolov3.network.Darknet.training",
"url":28,
"doc":""
},
{
"ref":"heyvi.model.yolov3.network.Darknet.forward",
"url":28,
"doc":"Defines the computation performed at every call. Should be overridden by all subclasses.  note Although the recipe for forward pass needs to be defined within this function, one should call the :class: Module instance afterwards instead of this since the former takes care of running the registered hooks while the latter silently ignores them.",
"func":1
},
{
"ref":"heyvi.model.yolov3.network.Darknet.load_darknet_weights",
"url":28,
"doc":"Parses and loads the weights stored in 'weights_path'",
"func":1
},
{
"ref":"heyvi.model.yolov3.network.Darknet.save_darknet_weights",
"url":28,
"doc":"@:param path - path of the new weights file @:param cutoff - save layers between 0 and cutoff (cutoff = -1 -> all are saved)",
"func":1
},
{
"ref":"heyvi.label",
"url":29,
"doc":""
},
{
"ref":"heyvi.label.Label",
"url":29,
"doc":""
},
{
"ref":"heyvi.label.piplabel_to_mevalabel",
"url":29,
"doc":"",
"func":1
},
{
"ref":"heyvi.label.mevalabel_to_index",
"url":29,
"doc":"",
"func":1
},
{
"ref":"heyvi.label.piplabel_to_index",
"url":29,
"doc":"",
"func":1
},
{
"ref":"heyvi.label.pip_250k_powerset",
"url":29,
"doc":"",
"func":1
},
{
"ref":"heyvi.version",
"url":30,
"doc":""
},
{
"ref":"heyvi.version.num",
"url":30,
"doc":"Convert the version string of the form 'X.Y.Z' to an integer 100000 X + 100 Y + Z for version comparison",
"func":1
},
{
"ref":"heyvi.version.split",
"url":30,
"doc":"Split the version string 'X.Y.Z' and return tuple (int(X), int(Y), int(Z ",
"func":1
},
{
"ref":"heyvi.version.major",
"url":30,
"doc":"Return the major version number int(X) for versionstring 'X.Y.Z'",
"func":1
},
{
"ref":"heyvi.version.minor",
"url":30,
"doc":"Return the minor version number int(Y) for versionstring 'X.Y.Z'",
"func":1
},
{
"ref":"heyvi.version.release",
"url":30,
"doc":"Return the release version number int(Z) for versionstring 'X.Y.Z'",
"func":1
},
{
"ref":"heyvi.version.at_least_version",
"url":30,
"doc":"Is versionstring='X.Y.Z' at least the current version?",
"func":1
},
{
"ref":"heyvi.version.is_at_least",
"url":30,
"doc":"Synonym for at_least_version",
"func":1
},
{
"ref":"heyvi.version.is_exactly",
"url":30,
"doc":"Is the versionstring = 'X,Y.Z' exactly equal to heyvi.__version__",
"func":1
},
{
"ref":"heyvi.version.at_least_major_version",
"url":30,
"doc":"is the major version (e.g. X, for version X.Y.Z) greater than or equal to the major version integer supplied?",
"func":1
},
{
"ref":"heyvi.recognition",
"url":31,
"doc":""
},
{
"ref":"heyvi.recognition.ActivityRecognition",
"url":31,
"doc":""
},
{
"ref":"heyvi.recognition.ActivityRecognition.class_to_index",
"url":31,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.index_to_class",
"url":31,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.classlist",
"url":31,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.num_classes",
"url":31,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.fromindex",
"url":31,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.label_confidence",
"url":31,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.activity",
"url":31,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.top1",
"url":31,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.topk",
"url":31,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.temporal_support",
"url":31,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.totensor",
"url":31,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityRecognition.binary_vector",
"url":31,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.PIP_250k",
"url":31,
"doc":"Activity recognition using people in public - 250k stabilized"
},
{
"ref":"heyvi.recognition.PIP_250k.dump_patches",
"url":31,
"doc":""
},
{
"ref":"heyvi.recognition.PIP_250k.training",
"url":31,
"doc":""
},
{
"ref":"heyvi.recognition.PIP_250k.category",
"url":31,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.PIP_250k.category_confidence",
"url":31,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.PIP_250k.topk",
"url":31,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.PIP_250k.topk_probability",
"url":31,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.PIP_250k.forward",
"url":31,
"doc":"Same as :meth: torch.nn.Module.forward() . Args:  args: Whatever you decide to pass into the forward method.  kwargs: Keyword arguments are also possible. Return: Your model's output",
"func":1
},
{
"ref":"heyvi.recognition.PIP_250k.configure_optimizers",
"url":31,
"doc":"Choose what optimizers and learning-rate schedulers to use in your optimization. Normally you'd need one. But in the case of GANs or similar you might have multiple. Return: Any of these 6 options. -  Single optimizer . -  List or Tuple of optimizers. -  Two lists - The first list has multiple optimizers, and the second has multiple LR schedulers (or multiple  lr_dict ). -  Dictionary , with an  \"optimizer\" key, and (optionally) a  \"lr_scheduler\" key whose value is a single LR scheduler or  lr_dict . -  Tuple of dictionaries as described above, with an optional  \"frequency\" key. -  None - Fit will run without any optimizer. The  lr_dict is a dictionary which contains the scheduler and its associated configuration. The default configuration is shown below.  code-block python lr_dict = {  REQUIRED: The scheduler instance \"scheduler\": lr_scheduler,  The unit of the scheduler's step size, could also be 'step'.  'epoch' updates the scheduler on epoch end whereas 'step'  updates it after a optimizer update. \"interval\": \"epoch\",  How many epochs/steps should pass between calls to   scheduler.step() . 1 corresponds to updating the learning  rate after every epoch/step. \"frequency\": 1,  Metric to to monitor for schedulers like  ReduceLROnPlateau \"monitor\": \"val_loss\",  If set to  True , will enforce that the value specified 'monitor'  is available when the scheduler is updated, thus stopping  training if not found. If set to  False , it will only produce a warning \"strict\": True,  If using the  LearningRateMonitor callback to monitor the  learning rate progress, this keyword can be used to specify  a custom logged name \"name\": None, } When there are schedulers in which the  .step() method is conditioned on a value, such as the :class: torch.optim.lr_scheduler.ReduceLROnPlateau scheduler, Lightning requires that the  lr_dict contains the keyword  \"monitor\" set to the metric name that the scheduler should be conditioned on.  testcode  The ReduceLROnPlateau scheduler requires a monitor def configure_optimizers(self): optimizer = Adam( .) return { \"optimizer\": optimizer, \"lr_scheduler\": { \"scheduler\": ReduceLROnPlateau(optimizer,  .), \"monitor\": \"metric_to_track\", }, }  In the case of two optimizers, only one using the ReduceLROnPlateau scheduler def configure_optimizers(self): optimizer1 = Adam( .) optimizer2 = SGD( .) scheduler1 = ReduceLROnPlateau(optimizer1,  .) scheduler2 = LambdaLR(optimizer2,  .) return ( { \"optimizer\": optimizer1, \"lr_scheduler\": { \"scheduler\": scheduler1, \"monitor\": \"metric_to_track\", }, }, {\"optimizer\": optimizer2, \"lr_scheduler\": scheduler2}, ) Metrics can be made available to monitor by simply logging it using  self.log('metric_to_track', metric_val) in your :class: ~pytorch_lightning.core.lightning.LightningModule . Note: The  frequency value specified in a dict along with the  optimizer key is an int corresponding to the number of sequential batches optimized with the specific optimizer. It should be given to none or to all of the optimizers. There is a difference between passing multiple optimizers in a list, and passing multiple optimizers in dictionaries with a frequency of 1: - In the former case, all optimizers will operate on the given batch in each optimization step. - In the latter, only one optimizer will operate on the given batch at every step. This is different from the  frequency value specified in the  lr_dict mentioned above.  code-block python def configure_optimizers(self): optimizer_one = torch.optim.SGD(self.model.parameters(), lr=0.01) optimizer_two = torch.optim.SGD(self.model.parameters(), lr=0.01) return [ {\"optimizer\": optimizer_one, \"frequency\": 5}, {\"optimizer\": optimizer_two, \"frequency\": 10}, ] In this example, the first optimizer will be used for the first 5 steps, the second optimizer for the next 10 steps and that cycle will continue. If an LR scheduler is specified for an optimizer using the  lr_scheduler key in the above dict, the scheduler will only be updated when its optimizer is being used. Examples  most cases. no learning rate scheduler def configure_optimizers(self): return Adam(self.parameters(), lr=1e-3)  multiple optimizer case (e.g.: GAN) def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) return gen_opt, dis_opt  example with learning rate schedulers def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) dis_sch = CosineAnnealing(dis_opt, T_max=10) return [gen_opt, dis_opt], [dis_sch]  example with step-based learning rate schedulers  each optimizer has its own scheduler def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) gen_sch = { 'scheduler': ExponentialLR(gen_opt, 0.99), 'interval': 'step'  called after each training step } dis_sch = CosineAnnealing(dis_opt, T_max=10)  called every epoch return [gen_opt, dis_opt], [gen_sch, dis_sch]  example with optimizer frequencies  see training procedure in  Improved Training of Wasserstein GANs , Algorithm 1  https: arxiv.org/abs/1704.00028 def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) n_critic = 5 return ( {'optimizer': dis_opt, 'frequency': n_critic}, {'optimizer': gen_opt, 'frequency': 1} ) Note: Some things to know: - Lightning calls  .backward() and  .step() on each optimizer and learning rate scheduler as needed. - If you use 16-bit precision ( precision=16 ), Lightning will automatically handle the optimizers. - If you use multiple optimizers, :meth: training_step will have an additional  optimizer_idx parameter. - If you use :class: torch.optim.LBFGS , Lightning handles the closure function automatically for you. - If you use multiple optimizers, gradients will be calculated only for the parameters of current optimizer at each training step. - If you need to control how often those optimizers step or override the default  .step() schedule, override the :meth: optimizer_step hook.",
"func":1
},
{
"ref":"heyvi.recognition.PIP_250k.training_step",
"url":31,
"doc":"Here you compute and return the training loss and some additional metrics for e.g. the progress bar or logger. Args: batch (:class: ~torch.Tensor | (:class: ~torch.Tensor ,  .) | [:class: ~torch.Tensor ,  .]): The output of your :class: ~torch.utils.data.DataLoader . A tensor, tuple or list. batch_idx (int): Integer displaying index of this batch optimizer_idx (int): When using multiple optimizers, this argument will also be present. hiddens(:class: ~torch.Tensor ): Passed in if :paramref: ~pytorch_lightning.core.lightning.LightningModule.truncated_bptt_steps > 0. Return: Any of. - :class: ~torch.Tensor - The loss tensor -  dict - A dictionary. Can include any keys, but must include the key  'loss' -  None - Training will skip to the next batch. This is only for automatic optimization. This is not supported for multi-GPU or TPU, or using  DeepSpeed . In this step you'd normally do the forward pass and calculate the loss for a batch. You can also do fancier things like multiple forward passes or something model specific. Example def training_step(self, batch, batch_idx): x, y, z = batch out = self.encoder(x) loss = self.loss(out, x) return loss If you define multiple optimizers, this step will be called with an additional  optimizer_idx parameter.  code-block python  Multiple optimizers (e.g.: GANs) def training_step(self, batch, batch_idx, optimizer_idx): if optimizer_idx  0:  do training_step with encoder  . if optimizer_idx  1:  do training_step with decoder  . If you add truncated back propagation through time you will also get an additional argument with the hidden states of the previous step.  code-block python  Truncated back-propagation through time def training_step(self, batch, batch_idx, hiddens):  hiddens are the hidden states from the previous truncated backprop step  . out, hiddens = self.lstm(data, hiddens)  . return {\"loss\": loss, \"hiddens\": hiddens} Note: The loss value shown in the progress bar is smoothed (averaged) over the last values, so it differs from the actual loss returned in train/validation step.",
"func":1
},
{
"ref":"heyvi.recognition.PIP_250k.validation_step",
"url":31,
"doc":"Operates on a single batch of data from the validation set. In this step you'd might generate examples or calculate anything of interest like accuracy.  code-block python  the pseudocode for these calls val_outs = [] for val_batch in val_data: out = validation_step(val_batch) val_outs.append(out) validation_epoch_end(val_outs) Args: batch (:class: ~torch.Tensor | (:class: ~torch.Tensor ,  .) | [:class: ~torch.Tensor ,  .]): The output of your :class: ~torch.utils.data.DataLoader . A tensor, tuple or list. batch_idx (int): The index of this batch dataloader_idx (int): The index of the dataloader that produced this batch (only if multiple val dataloaders used) Return: - Any object or value -  None - Validation will skip to the next batch  code-block python  pseudocode of order val_outs = [] for val_batch in val_data: out = validation_step(val_batch) if defined(\"validation_step_end\"): out = validation_step_end(out) val_outs.append(out) val_outs = validation_epoch_end(val_outs)  code-block python  if you have one val dataloader: def validation_step(self, batch, batch_idx):  .  if you have multiple val dataloaders: def validation_step(self, batch, batch_idx, dataloader_idx):  . Examples  CASE 1: A single validation dataset def validation_step(self, batch, batch_idx): x, y = batch  implement your own out = self(x) loss = self.loss(out, y)  log 6 example images  or generated text . or whatever sample_imgs = x[:6] grid = torchvision.utils.make_grid(sample_imgs) self.logger.experiment.add_image('example_images', grid, 0)  calculate acc labels_hat = torch.argmax(out, dim=1) val_acc = torch.sum(y  labels_hat).item() / (len(y)  1.0)  log the outputs! self.log_dict({'val_loss': loss, 'val_acc': val_acc}) If you pass in multiple val dataloaders, :meth: validation_step will have an additional argument.  code-block python  CASE 2: multiple validation dataloaders def validation_step(self, batch, batch_idx, dataloader_idx):  dataloader_idx tells you which dataset this is.  . Note: If you don't need to validate you don't need to implement this method. Note: When the :meth: validation_step is called, the model has been put in eval mode and PyTorch gradients have been disabled. At the end of validation, the model goes back to training mode and gradients are enabled.",
"func":1
},
{
"ref":"heyvi.recognition.PIP_250k.validation_epoch_end",
"url":31,
"doc":"Called at the end of the validation epoch with the outputs of all validation steps.  code-block python  the pseudocode for these calls val_outs = [] for val_batch in val_data: out = validation_step(val_batch) val_outs.append(out) validation_epoch_end(val_outs) Args: outputs: List of outputs you defined in :meth: validation_step , or if there are multiple dataloaders, a list containing a list of outputs for each dataloader. Return: None Note: If you didn't define a :meth: validation_step , this won't be called. Examples: With a single dataloader:  code-block python def validation_epoch_end(self, val_step_outputs): for out in val_step_outputs:  . With multiple dataloaders,  outputs will be a list of lists. The outer list contains one entry per dataloader, while the inner list contains the individual outputs of each validation step for that dataloader.  code-block python def validation_epoch_end(self, outputs): for dataloader_output_result in outputs: dataloader_outs = dataloader_output_result.dataloader_i_outputs self.log(\"final_metric\", final_value)",
"func":1
},
{
"ref":"heyvi.recognition.PIP_250k.from_checkpoint",
"url":31,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.PIP_250k.totensor",
"url":31,
"doc":"Return captured lambda function if v=None, else return tensor",
"func":1
},
{
"ref":"heyvi.recognition.PIP_370k",
"url":31,
"doc":"Activity recognition using people in public - 250k stabilized"
},
{
"ref":"heyvi.recognition.PIP_370k.dump_patches",
"url":31,
"doc":""
},
{
"ref":"heyvi.recognition.PIP_370k.training",
"url":31,
"doc":""
},
{
"ref":"heyvi.recognition.PIP_370k.forward",
"url":31,
"doc":"Same as :meth: torch.nn.Module.forward() . Args:  args: Whatever you decide to pass into the forward method.  kwargs: Keyword arguments are also possible. Return: Your model's output",
"func":1
},
{
"ref":"heyvi.recognition.PIP_370k.topk",
"url":31,
"doc":"Return the top-k classes for a 3 second activity proposal along with framewise ground truth",
"func":1
},
{
"ref":"heyvi.recognition.PIP_370k.totensor",
"url":31,
"doc":"Return captured lambda function if v=None, else return tensor",
"func":1
},
{
"ref":"heyvi.recognition.PIP_370k.configure_optimizers",
"url":31,
"doc":"Choose what optimizers and learning-rate schedulers to use in your optimization. Normally you'd need one. But in the case of GANs or similar you might have multiple. Return: Any of these 6 options. -  Single optimizer . -  List or Tuple of optimizers. -  Two lists - The first list has multiple optimizers, and the second has multiple LR schedulers (or multiple  lr_dict ). -  Dictionary , with an  \"optimizer\" key, and (optionally) a  \"lr_scheduler\" key whose value is a single LR scheduler or  lr_dict . -  Tuple of dictionaries as described above, with an optional  \"frequency\" key. -  None - Fit will run without any optimizer. The  lr_dict is a dictionary which contains the scheduler and its associated configuration. The default configuration is shown below.  code-block python lr_dict = {  REQUIRED: The scheduler instance \"scheduler\": lr_scheduler,  The unit of the scheduler's step size, could also be 'step'.  'epoch' updates the scheduler on epoch end whereas 'step'  updates it after a optimizer update. \"interval\": \"epoch\",  How many epochs/steps should pass between calls to   scheduler.step() . 1 corresponds to updating the learning  rate after every epoch/step. \"frequency\": 1,  Metric to to monitor for schedulers like  ReduceLROnPlateau \"monitor\": \"val_loss\",  If set to  True , will enforce that the value specified 'monitor'  is available when the scheduler is updated, thus stopping  training if not found. If set to  False , it will only produce a warning \"strict\": True,  If using the  LearningRateMonitor callback to monitor the  learning rate progress, this keyword can be used to specify  a custom logged name \"name\": None, } When there are schedulers in which the  .step() method is conditioned on a value, such as the :class: torch.optim.lr_scheduler.ReduceLROnPlateau scheduler, Lightning requires that the  lr_dict contains the keyword  \"monitor\" set to the metric name that the scheduler should be conditioned on.  testcode  The ReduceLROnPlateau scheduler requires a monitor def configure_optimizers(self): optimizer = Adam( .) return { \"optimizer\": optimizer, \"lr_scheduler\": { \"scheduler\": ReduceLROnPlateau(optimizer,  .), \"monitor\": \"metric_to_track\", }, }  In the case of two optimizers, only one using the ReduceLROnPlateau scheduler def configure_optimizers(self): optimizer1 = Adam( .) optimizer2 = SGD( .) scheduler1 = ReduceLROnPlateau(optimizer1,  .) scheduler2 = LambdaLR(optimizer2,  .) return ( { \"optimizer\": optimizer1, \"lr_scheduler\": { \"scheduler\": scheduler1, \"monitor\": \"metric_to_track\", }, }, {\"optimizer\": optimizer2, \"lr_scheduler\": scheduler2}, ) Metrics can be made available to monitor by simply logging it using  self.log('metric_to_track', metric_val) in your :class: ~pytorch_lightning.core.lightning.LightningModule . Note: The  frequency value specified in a dict along with the  optimizer key is an int corresponding to the number of sequential batches optimized with the specific optimizer. It should be given to none or to all of the optimizers. There is a difference between passing multiple optimizers in a list, and passing multiple optimizers in dictionaries with a frequency of 1: - In the former case, all optimizers will operate on the given batch in each optimization step. - In the latter, only one optimizer will operate on the given batch at every step. This is different from the  frequency value specified in the  lr_dict mentioned above.  code-block python def configure_optimizers(self): optimizer_one = torch.optim.SGD(self.model.parameters(), lr=0.01) optimizer_two = torch.optim.SGD(self.model.parameters(), lr=0.01) return [ {\"optimizer\": optimizer_one, \"frequency\": 5}, {\"optimizer\": optimizer_two, \"frequency\": 10}, ] In this example, the first optimizer will be used for the first 5 steps, the second optimizer for the next 10 steps and that cycle will continue. If an LR scheduler is specified for an optimizer using the  lr_scheduler key in the above dict, the scheduler will only be updated when its optimizer is being used. Examples  most cases. no learning rate scheduler def configure_optimizers(self): return Adam(self.parameters(), lr=1e-3)  multiple optimizer case (e.g.: GAN) def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) return gen_opt, dis_opt  example with learning rate schedulers def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) dis_sch = CosineAnnealing(dis_opt, T_max=10) return [gen_opt, dis_opt], [dis_sch]  example with step-based learning rate schedulers  each optimizer has its own scheduler def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) gen_sch = { 'scheduler': ExponentialLR(gen_opt, 0.99), 'interval': 'step'  called after each training step } dis_sch = CosineAnnealing(dis_opt, T_max=10)  called every epoch return [gen_opt, dis_opt], [gen_sch, dis_sch]  example with optimizer frequencies  see training procedure in  Improved Training of Wasserstein GANs , Algorithm 1  https: arxiv.org/abs/1704.00028 def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) n_critic = 5 return ( {'optimizer': dis_opt, 'frequency': n_critic}, {'optimizer': gen_opt, 'frequency': 1} ) Note: Some things to know: - Lightning calls  .backward() and  .step() on each optimizer and learning rate scheduler as needed. - If you use 16-bit precision ( precision=16 ), Lightning will automatically handle the optimizers. - If you use multiple optimizers, :meth: training_step will have an additional  optimizer_idx parameter. - If you use :class: torch.optim.LBFGS , Lightning handles the closure function automatically for you. - If you use multiple optimizers, gradients will be calculated only for the parameters of current optimizer at each training step. - If you need to control how often those optimizers step or override the default  .step() schedule, override the :meth: optimizer_step hook.",
"func":1
},
{
"ref":"heyvi.recognition.PIP_370k.training_step",
"url":31,
"doc":"Here you compute and return the training loss and some additional metrics for e.g. the progress bar or logger. Args: batch (:class: ~torch.Tensor | (:class: ~torch.Tensor ,  .) | [:class: ~torch.Tensor ,  .]): The output of your :class: ~torch.utils.data.DataLoader . A tensor, tuple or list. batch_idx (int): Integer displaying index of this batch optimizer_idx (int): When using multiple optimizers, this argument will also be present. hiddens(:class: ~torch.Tensor ): Passed in if :paramref: ~pytorch_lightning.core.lightning.LightningModule.truncated_bptt_steps > 0. Return: Any of. - :class: ~torch.Tensor - The loss tensor -  dict - A dictionary. Can include any keys, but must include the key  'loss' -  None - Training will skip to the next batch. This is only for automatic optimization. This is not supported for multi-GPU or TPU, or using  DeepSpeed . In this step you'd normally do the forward pass and calculate the loss for a batch. You can also do fancier things like multiple forward passes or something model specific. Example def training_step(self, batch, batch_idx): x, y, z = batch out = self.encoder(x) loss = self.loss(out, x) return loss If you define multiple optimizers, this step will be called with an additional  optimizer_idx parameter.  code-block python  Multiple optimizers (e.g.: GANs) def training_step(self, batch, batch_idx, optimizer_idx): if optimizer_idx  0:  do training_step with encoder  . if optimizer_idx  1:  do training_step with decoder  . If you add truncated back propagation through time you will also get an additional argument with the hidden states of the previous step.  code-block python  Truncated back-propagation through time def training_step(self, batch, batch_idx, hiddens):  hiddens are the hidden states from the previous truncated backprop step  . out, hiddens = self.lstm(data, hiddens)  . return {\"loss\": loss, \"hiddens\": hiddens} Note: The loss value shown in the progress bar is smoothed (averaged) over the last values, so it differs from the actual loss returned in train/validation step.",
"func":1
},
{
"ref":"heyvi.recognition.PIP_370k.validation_step",
"url":31,
"doc":"Operates on a single batch of data from the validation set. In this step you'd might generate examples or calculate anything of interest like accuracy.  code-block python  the pseudocode for these calls val_outs = [] for val_batch in val_data: out = validation_step(val_batch) val_outs.append(out) validation_epoch_end(val_outs) Args: batch (:class: ~torch.Tensor | (:class: ~torch.Tensor ,  .) | [:class: ~torch.Tensor ,  .]): The output of your :class: ~torch.utils.data.DataLoader . A tensor, tuple or list. batch_idx (int): The index of this batch dataloader_idx (int): The index of the dataloader that produced this batch (only if multiple val dataloaders used) Return: - Any object or value -  None - Validation will skip to the next batch  code-block python  pseudocode of order val_outs = [] for val_batch in val_data: out = validation_step(val_batch) if defined(\"validation_step_end\"): out = validation_step_end(out) val_outs.append(out) val_outs = validation_epoch_end(val_outs)  code-block python  if you have one val dataloader: def validation_step(self, batch, batch_idx):  .  if you have multiple val dataloaders: def validation_step(self, batch, batch_idx, dataloader_idx):  . Examples  CASE 1: A single validation dataset def validation_step(self, batch, batch_idx): x, y = batch  implement your own out = self(x) loss = self.loss(out, y)  log 6 example images  or generated text . or whatever sample_imgs = x[:6] grid = torchvision.utils.make_grid(sample_imgs) self.logger.experiment.add_image('example_images', grid, 0)  calculate acc labels_hat = torch.argmax(out, dim=1) val_acc = torch.sum(y  labels_hat).item() / (len(y)  1.0)  log the outputs! self.log_dict({'val_loss': loss, 'val_acc': val_acc}) If you pass in multiple val dataloaders, :meth: validation_step will have an additional argument.  code-block python  CASE 2: multiple validation dataloaders def validation_step(self, batch, batch_idx, dataloader_idx):  dataloader_idx tells you which dataset this is.  . Note: If you don't need to validate you don't need to implement this method. Note: When the :meth: validation_step is called, the model has been put in eval mode and PyTorch gradients have been disabled. At the end of validation, the model goes back to training mode and gradients are enabled.",
"func":1
},
{
"ref":"heyvi.recognition.PIP_370k.validation_epoch_end",
"url":31,
"doc":"Called at the end of the validation epoch with the outputs of all validation steps.  code-block python  the pseudocode for these calls val_outs = [] for val_batch in val_data: out = validation_step(val_batch) val_outs.append(out) validation_epoch_end(val_outs) Args: outputs: List of outputs you defined in :meth: validation_step , or if there are multiple dataloaders, a list containing a list of outputs for each dataloader. Return: None Note: If you didn't define a :meth: validation_step , this won't be called. Examples: With a single dataloader:  code-block python def validation_epoch_end(self, val_step_outputs): for out in val_step_outputs:  . With multiple dataloaders,  outputs will be a list of lists. The outer list contains one entry per dataloader, while the inner list contains the individual outputs of each validation step for that dataloader.  code-block python def validation_epoch_end(self, outputs): for dataloader_output_result in outputs: dataloader_outs = dataloader_output_result.dataloader_i_outputs self.log(\"final_metric\", final_value)",
"func":1
},
{
"ref":"heyvi.recognition.ActivityTracker",
"url":31,
"doc":"Video Activity detection. Args (__call__): vi [generator of  vipy.video.Scene ]: The input video to be updated in place with detections. This is a generator which is output from heyvi.detection.MultiscaleVideoTracker.__call__ activityiou [float]: The minimum temporal iou for activity assignment mirror [bool]: If true, encode using the mean of a video encoding and the mirrored video encoding. This is slower as it requires 2x GPU forward passes minprob [float]: The minimum probability for new activity detection trackconf [float]: The minimum object detection confidence for new tracks maxdets [int]: The maximum number of allowable detections per frame. If there are more detections per frame tha maxdets, sort them by confidence and use only the top maxdets best avgdets [int]: The number of allowable detections per frame if throttled buffered [bool]: If true, then buffer streams. This is useful for activity detection on live streams. finalized [bool, int]: If False then do not finalize(), If True finalize() only at the end, If int, then finalize every int frames. This is useful for streaming activity detection on unbounded inputs. Returns: The input video is updated in place."
},
{
"ref":"heyvi.recognition.ActivityTracker.dump_patches",
"url":31,
"doc":""
},
{
"ref":"heyvi.recognition.ActivityTracker.training",
"url":31,
"doc":""
},
{
"ref":"heyvi.recognition.ActivityTracker.temporal_stride",
"url":31,
"doc":"",
"func":1
},
{
"ref":"heyvi.recognition.ActivityTracker.forward",
"url":31,
"doc":"Overload forward for multi-gpu batch. Don't use torch DataParallel!",
"func":1
},
{
"ref":"heyvi.recognition.ActivityTracker.lrt",
"url":31,
"doc":"top-k with likelihood ratio test with background null hypothesis",
"func":1
},
{
"ref":"heyvi.recognition.ActivityTracker.finalize",
"url":31,
"doc":"In place filtering of video to finalize",
"func":1
},
{
"ref":"heyvi.recognition.ActivityTracker.topk",
"url":31,
"doc":"Return the top-k classes for a 3 second activity proposal along with framewise ground truth",
"func":1
},
{
"ref":"heyvi.recognition.ActivityTracker.totensor",
"url":31,
"doc":"Return captured lambda function if v=None, else return tensor",
"func":1
},
{
"ref":"heyvi.recognition.ActivityTracker.configure_optimizers",
"url":31,
"doc":"Choose what optimizers and learning-rate schedulers to use in your optimization. Normally you'd need one. But in the case of GANs or similar you might have multiple. Return: Any of these 6 options. -  Single optimizer . -  List or Tuple of optimizers. -  Two lists - The first list has multiple optimizers, and the second has multiple LR schedulers (or multiple  lr_dict ). -  Dictionary , with an  \"optimizer\" key, and (optionally) a  \"lr_scheduler\" key whose value is a single LR scheduler or  lr_dict . -  Tuple of dictionaries as described above, with an optional  \"frequency\" key. -  None - Fit will run without any optimizer. The  lr_dict is a dictionary which contains the scheduler and its associated configuration. The default configuration is shown below.  code-block python lr_dict = {  REQUIRED: The scheduler instance \"scheduler\": lr_scheduler,  The unit of the scheduler's step size, could also be 'step'.  'epoch' updates the scheduler on epoch end whereas 'step'  updates it after a optimizer update. \"interval\": \"epoch\",  How many epochs/steps should pass between calls to   scheduler.step() . 1 corresponds to updating the learning  rate after every epoch/step. \"frequency\": 1,  Metric to to monitor for schedulers like  ReduceLROnPlateau \"monitor\": \"val_loss\",  If set to  True , will enforce that the value specified 'monitor'  is available when the scheduler is updated, thus stopping  training if not found. If set to  False , it will only produce a warning \"strict\": True,  If using the  LearningRateMonitor callback to monitor the  learning rate progress, this keyword can be used to specify  a custom logged name \"name\": None, } When there are schedulers in which the  .step() method is conditioned on a value, such as the :class: torch.optim.lr_scheduler.ReduceLROnPlateau scheduler, Lightning requires that the  lr_dict contains the keyword  \"monitor\" set to the metric name that the scheduler should be conditioned on.  testcode  The ReduceLROnPlateau scheduler requires a monitor def configure_optimizers(self): optimizer = Adam( .) return { \"optimizer\": optimizer, \"lr_scheduler\": { \"scheduler\": ReduceLROnPlateau(optimizer,  .), \"monitor\": \"metric_to_track\", }, }  In the case of two optimizers, only one using the ReduceLROnPlateau scheduler def configure_optimizers(self): optimizer1 = Adam( .) optimizer2 = SGD( .) scheduler1 = ReduceLROnPlateau(optimizer1,  .) scheduler2 = LambdaLR(optimizer2,  .) return ( { \"optimizer\": optimizer1, \"lr_scheduler\": { \"scheduler\": scheduler1, \"monitor\": \"metric_to_track\", }, }, {\"optimizer\": optimizer2, \"lr_scheduler\": scheduler2}, ) Metrics can be made available to monitor by simply logging it using  self.log('metric_to_track', metric_val) in your :class: ~pytorch_lightning.core.lightning.LightningModule . Note: The  frequency value specified in a dict along with the  optimizer key is an int corresponding to the number of sequential batches optimized with the specific optimizer. It should be given to none or to all of the optimizers. There is a difference between passing multiple optimizers in a list, and passing multiple optimizers in dictionaries with a frequency of 1: - In the former case, all optimizers will operate on the given batch in each optimization step. - In the latter, only one optimizer will operate on the given batch at every step. This is different from the  frequency value specified in the  lr_dict mentioned above.  code-block python def configure_optimizers(self): optimizer_one = torch.optim.SGD(self.model.parameters(), lr=0.01) optimizer_two = torch.optim.SGD(self.model.parameters(), lr=0.01) return [ {\"optimizer\": optimizer_one, \"frequency\": 5}, {\"optimizer\": optimizer_two, \"frequency\": 10}, ] In this example, the first optimizer will be used for the first 5 steps, the second optimizer for the next 10 steps and that cycle will continue. If an LR scheduler is specified for an optimizer using the  lr_scheduler key in the above dict, the scheduler will only be updated when its optimizer is being used. Examples  most cases. no learning rate scheduler def configure_optimizers(self): return Adam(self.parameters(), lr=1e-3)  multiple optimizer case (e.g.: GAN) def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) return gen_opt, dis_opt  example with learning rate schedulers def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) dis_sch = CosineAnnealing(dis_opt, T_max=10) return [gen_opt, dis_opt], [dis_sch]  example with step-based learning rate schedulers  each optimizer has its own scheduler def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) gen_sch = { 'scheduler': ExponentialLR(gen_opt, 0.99), 'interval': 'step'  called after each training step } dis_sch = CosineAnnealing(dis_opt, T_max=10)  called every epoch return [gen_opt, dis_opt], [gen_sch, dis_sch]  example with optimizer frequencies  see training procedure in  Improved Training of Wasserstein GANs , Algorithm 1  https: arxiv.org/abs/1704.00028 def configure_optimizers(self): gen_opt = Adam(self.model_gen.parameters(), lr=0.01) dis_opt = Adam(self.model_dis.parameters(), lr=0.02) n_critic = 5 return ( {'optimizer': dis_opt, 'frequency': n_critic}, {'optimizer': gen_opt, 'frequency': 1} ) Note: Some things to know: - Lightning calls  .backward() and  .step() on each optimizer and learning rate scheduler as needed. - If you use 16-bit precision ( precision=16 ), Lightning will automatically handle the optimizers. - If you use multiple optimizers, :meth: training_step will have an additional  optimizer_idx parameter. - If you use :class: torch.optim.LBFGS , Lightning handles the closure function automatically for you. - If you use multiple optimizers, gradients will be calculated only for the parameters of current optimizer at each training step. - If you need to control how often those optimizers step or override the default  .step() schedule, override the :meth: optimizer_step hook.",
"func":1
},
{
"ref":"heyvi.recognition.ActivityTracker.training_step",
"url":31,
"doc":"Here you compute and return the training loss and some additional metrics for e.g. the progress bar or logger. Args: batch (:class: ~torch.Tensor | (:class: ~torch.Tensor ,  .) | [:class: ~torch.Tensor ,  .]): The output of your :class: ~torch.utils.data.DataLoader . A tensor, tuple or list. batch_idx (int): Integer displaying index of this batch optimizer_idx (int): When using multiple optimizers, this argument will also be present. hiddens(:class: ~torch.Tensor ): Passed in if :paramref: ~pytorch_lightning.core.lightning.LightningModule.truncated_bptt_steps > 0. Return: Any of. - :class: ~torch.Tensor - The loss tensor -  dict - A dictionary. Can include any keys, but must include the key  'loss' -  None - Training will skip to the next batch. This is only for automatic optimization. This is not supported for multi-GPU or TPU, or using  DeepSpeed . In this step you'd normally do the forward pass and calculate the loss for a batch. You can also do fancier things like multiple forward passes or something model specific. Example def training_step(self, batch, batch_idx): x, y, z = batch out = self.encoder(x) loss = self.loss(out, x) return loss If you define multiple optimizers, this step will be called with an additional  optimizer_idx parameter.  code-block python  Multiple optimizers (e.g.: GANs) def training_step(self, batch, batch_idx, optimizer_idx): if optimizer_idx  0:  do training_step with encoder  . if optimizer_idx  1:  do training_step with decoder  . If you add truncated back propagation through time you will also get an additional argument with the hidden states of the previous step.  code-block python  Truncated back-propagation through time def training_step(self, batch, batch_idx, hiddens):  hiddens are the hidden states from the previous truncated backprop step  . out, hiddens = self.lstm(data, hiddens)  . return {\"loss\": loss, \"hiddens\": hiddens} Note: The loss value shown in the progress bar is smoothed (averaged) over the last values, so it differs from the actual loss returned in train/validation step.",
"func":1
},
{
"ref":"heyvi.recognition.ActivityTracker.validation_step",
"url":31,
"doc":"Operates on a single batch of data from the validation set. In this step you'd might generate examples or calculate anything of interest like accuracy.  code-block python  the pseudocode for these calls val_outs = [] for val_batch in val_data: out = validation_step(val_batch) val_outs.append(out) validation_epoch_end(val_outs) Args: batch (:class: ~torch.Tensor | (:class: ~torch.Tensor ,  .) | [:class: ~torch.Tensor ,  .]): The output of your :class: ~torch.utils.data.DataLoader . A tensor, tuple or list. batch_idx (int): The index of this batch dataloader_idx (int): The index of the dataloader that produced this batch (only if multiple val dataloaders used) Return: - Any object or value -  None - Validation will skip to the next batch  code-block python  pseudocode of order val_outs = [] for val_batch in val_data: out = validation_step(val_batch) if defined(\"validation_step_end\"): out = validation_step_end(out) val_outs.append(out) val_outs = validation_epoch_end(val_outs)  code-block python  if you have one val dataloader: def validation_step(self, batch, batch_idx):  .  if you have multiple val dataloaders: def validation_step(self, batch, batch_idx, dataloader_idx):  . Examples  CASE 1: A single validation dataset def validation_step(self, batch, batch_idx): x, y = batch  implement your own out = self(x) loss = self.loss(out, y)  log 6 example images  or generated text . or whatever sample_imgs = x[:6] grid = torchvision.utils.make_grid(sample_imgs) self.logger.experiment.add_image('example_images', grid, 0)  calculate acc labels_hat = torch.argmax(out, dim=1) val_acc = torch.sum(y  labels_hat).item() / (len(y)  1.0)  log the outputs! self.log_dict({'val_loss': loss, 'val_acc': val_acc}) If you pass in multiple val dataloaders, :meth: validation_step will have an additional argument.  code-block python  CASE 2: multiple validation dataloaders def validation_step(self, batch, batch_idx, dataloader_idx):  dataloader_idx tells you which dataset this is.  . Note: If you don't need to validate you don't need to implement this method. Note: When the :meth: validation_step is called, the model has been put in eval mode and PyTorch gradients have been disabled. At the end of validation, the model goes back to training mode and gradients are enabled.",
"func":1
},
{
"ref":"heyvi.recognition.ActivityTracker.validation_epoch_end",
"url":31,
"doc":"Called at the end of the validation epoch with the outputs of all validation steps.  code-block python  the pseudocode for these calls val_outs = [] for val_batch in val_data: out = validation_step(val_batch) val_outs.append(out) validation_epoch_end(val_outs) Args: outputs: List of outputs you defined in :meth: validation_step , or if there are multiple dataloaders, a list containing a list of outputs for each dataloader. Return: None Note: If you didn't define a :meth: validation_step , this won't be called. Examples: With a single dataloader:  code-block python def validation_epoch_end(self, val_step_outputs): for out in val_step_outputs:  . With multiple dataloaders,  outputs will be a list of lists. The outer list contains one entry per dataloader, while the inner list contains the individual outputs of each validation step for that dataloader.  code-block python def validation_epoch_end(self, outputs): for dataloader_output_result in outputs: dataloader_outs = dataloader_output_result.dataloader_i_outputs self.log(\"final_metric\", final_value)",
"func":1
},
{
"ref":"heyvi.util",
"url":32,
"doc":""
},
{
"ref":"heyvi.util.timestamp",
"url":32,
"doc":"Datetime stamp in eastern timezone with microsecond resolution",
"func":1
},
{
"ref":"heyvi.detection",
"url":33,
"doc":""
},
{
"ref":"heyvi.detection.TorchNet",
"url":33,
"doc":""
},
{
"ref":"heyvi.detection.TorchNet.gpu",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.TorchNet.cpu",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.TorchNet.iscpu",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.TorchNet.isgpu",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.TorchNet.batchsize",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.FaceDetector",
"url":33,
"doc":"Faster R-CNN based face detector"
},
{
"ref":"heyvi.detection.FaceDetector.batchsize",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.Yolov5",
"url":33,
"doc":"Yolov5 based object detector >>> d = heyvi.detection.Detector() >>> d(vipy.image.vehicles( .show()"
},
{
"ref":"heyvi.detection.Yolov5.classlist",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.Yolov3",
"url":33,
"doc":"Yolov3 based object detector >>> d = heyvi.detection.Detector() >>> d(vipy.image.vehicles( .show()"
},
{
"ref":"heyvi.detection.Yolov3.classlist",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.ObjectDetector",
"url":33,
"doc":"Default object detector"
},
{
"ref":"heyvi.detection.MultiscaleObjectDetector",
"url":33,
"doc":"Given a list of images, break each one into a set of overlapping tiles, and ObjectDetector() on each, then recombining detections"
},
{
"ref":"heyvi.detection.VideoDetector",
"url":33,
"doc":"Iterate ObjectDetector() over each frame of video, yielding the detected frame"
},
{
"ref":"heyvi.detection.MultiscaleVideoDetector",
"url":33,
"doc":"Given a list of images, break each one into a set of overlapping tiles, and ObjectDetector() on each, then recombining detections"
},
{
"ref":"heyvi.detection.VideoTracker",
"url":33,
"doc":"Default object detector"
},
{
"ref":"heyvi.detection.VideoTracker.track",
"url":33,
"doc":"Batch tracking",
"func":1
},
{
"ref":"heyvi.detection.FaceTracker",
"url":33,
"doc":"Faster R-CNN based face detector"
},
{
"ref":"heyvi.detection.FaceTracker.track",
"url":33,
"doc":"Batch tracking",
"func":1
},
{
"ref":"heyvi.detection.MultiscaleVideoTracker",
"url":33,
"doc":"MultiscaleVideoTracker() class"
},
{
"ref":"heyvi.detection.MultiscaleVideoTracker.stream",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.MultiscaleVideoTracker.track",
"url":33,
"doc":"Batch tracking",
"func":1
},
{
"ref":"heyvi.detection.Proposal",
"url":33,
"doc":"Default object detector"
},
{
"ref":"heyvi.detection.VideoProposal",
"url":33,
"doc":"heyvi.detection.VideoProposal() class. Track-based object proposals in video."
},
{
"ref":"heyvi.detection.VideoProposal.allowable_objects",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.VideoProposal.isallowable",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.FaceProposalRefinement",
"url":33,
"doc":""
},
{
"ref":"heyvi.detection.TrackProposalRefinement",
"url":33,
"doc":""
},
{
"ref":"heyvi.detection.VideoProposalRefinement",
"url":33,
"doc":"heyvi.detection.VideoProposalRefinement() class. Track-based object proposal refinement of a weakly supervised loose object box from a human annotator."
},
{
"ref":"heyvi.detection.ActorAssociation",
"url":33,
"doc":"heyvi.detection.VideoAssociation() class Select the best object track of the target class associated with the primary actor class by gated spatial IOU and distance. Add the best object track to the scene and associate with all activities performed by the primary actor."
},
{
"ref":"heyvi.detection.ActorAssociation.isallowable",
"url":33,
"doc":"",
"func":1
},
{
"ref":"heyvi.detection.ActorAssociation.track",
"url":33,
"doc":"Batch tracking",
"func":1
}
]